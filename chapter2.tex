\chapter{Basic Operations in Riemannian Space}
\pagebreak[4]

\section{p27-exercise}

\begin{tcolorbox}
Take polar coordinates $r, \theta$ in a plane. Draw the infinitesimal triangle with vertices $(r,\theta)$, $(r+dr,\theta)$, $(r,\theta + d\theta)$. Evaluate the square on the hypotenuse of this infinitisimal triangle, and so obtain the metric tensor for the plan for the coordinates$(r, \theta)$.\end{tcolorbox}
\begin{figure}[htp] 
    \centering
\includegraphics[scale=.5]{polar.jpg}
\end{figure}
\begin{align} 
\ ds^2 &= |AB|^2\\
\ &= dr^2 +|CA|^2\\
\ |CA| &= r\sin(d\theta)\approx rd\theta\\
\Rightarrow ds^2 &= dr^2 + r^2d\theta^2\\
\Rightarrow (a_{mn}) &= \begin{pmatrix}
 1& 0 \\
0 & r^2 \\
\end{pmatrix}
\end{align}
$$\medblackdiamond$$
\pagebreak[4]

\section{p27-exercise}

\begin{tcolorbox}
Show that if $x^1 = r, x^2 = \theta, x^3 = \phi$, in the usual notation of spherical polar coordinates, then $$ a_{11} =1, a_{22} = r^2, a_{33} = r^2\sin^2\theta$$ and the other components vanish.
\end{tcolorbox}
\begin{figure}[h]
\centering
\begin{minipage}[t]{.5\textwidth}
%\centering
\vspace{0pt}
\includegraphics[scale=.5]{spherical.jpg}
\end{minipage}\hfill
\begin{minipage}[t]{0.4\textwidth}
%\centering
\vspace{50pt}
We use the latitude $\psi$ instead of the co-latitude $\phi$.\\\\
$\left\{ \begin{array}{c}
    x= r\cos (\psi )\cos (\theta) \\
     y= r\cos (\psi )\sin (\theta) \\
      z= r\sin(\psi )
  \end{array} \right.$
\end{minipage}
\end{figure}
\begin{align} 
\ ds^2 = dx^2 + dy^2 + dz^2\quad\text{with}\\
\left.
\begin{array}{c}
    dx= dr\cos (\psi )\cos (\theta)- r\sin (\psi )d\psi\cos (\theta) -r\cos (\psi )\sin (\theta)d\theta\\
     dy= dr\cos (\psi )\sin (\theta) -r\sin (\psi )d\psi\sin (\theta)+r\cos (\psi )\cos (\theta)d\theta\\
      dz= dr\sin(\psi )+r\cos(\psi )d\psi\\
  \end{array} \right\}
  \end{align}
  \begin{align}
  \left.
  \begin{array}{c}
    dx^2=
    \cos^2 (\psi )\cos^2 (\theta)dr^2\\- r^2\sin^2 (\psi )\cos^2 (\theta)d\psi^2\\ -r^2\cos^2 (\psi )\sin^2 (\theta)d\theta^2\\
    -\cos (\psi )\cos (\theta) r\sin (\psi )\cos (\theta)drd\psi\\
    -\cos (\psi )\cos (\theta)r\cos (\psi )\sin (\theta)drd\theta\\
    +r\sin (\psi )\cos (\theta)r\cos (\psi )\sin (\theta)d\psi d\theta  \\\\
     dy^2=  \cos^2 (\psi )\sin^2 (\theta)dr^2\\ +r^2\sin^2 (\psi )\sin^2 (\theta)d\psi^2\\+r^2\cos^2 (\psi )\cos^2 (\theta)d\theta^2\\-\cos (\psi )\sin (\theta)r\sin (\psi )\sin (\theta)dr d\psi\\ - \cos (\psi )\sin (\theta)r\cos (\psi )\cos (\theta)drd\theta\\
     -r\sin (\psi )\sin (\theta)r\cos (\psi )\cos (\theta)d\psi d\theta\\\\
      dz^2= \sin^2(\psi )dr^2 +r^2\cos^2(\psi )d\psi^2 + r\sin(\psi )\cos(\psi )drd\psi\\
  \end{array} \right\}
\end{align}
Rearrange terms:
  \begin{align}
  \left.
  \begin{array}{c}
    dx^2=
    \cos^2 (\psi )\cos^2 (\theta)dr^2\\+ r^2\sin^2 (\psi )\cos^2 (\theta)d\psi^2\\ +r^2\cos^2 (\psi )\sin^2 (\theta)d\theta^2\\
    -r\cos (\psi )\sin (\psi )\cos^2 (\theta)drd\psi\\
    -r\cos^2 (\psi )\cos (\theta)\sin (\theta)drd\theta\\
    +r^2\sin (\psi )\cos (\theta) \cos (\psi )\sin (\theta)d\psi d\theta  \\\\
     dy^2=  \cos^2 (\psi )\sin^2 (\theta)dr^2\\ +r^2\sin^2 (\psi )\sin^2 (\theta)d\psi^2\\+r^2\cos^2 (\psi )\cos^2 (\theta)d\theta^2\\-r\cos (\psi )\sin (\psi )\sin^2 (\theta)dr d\psi\\ - r\cos^2 (\psi )\sin (\theta) \cos (\theta)drd\theta\\
     -r^2\sin (\psi )\sin (\theta)\cos (\psi )\cos (\theta)d\psi d\theta\\\\
      dz^2= \sin^2(\psi )dr^2 +r^2\cos^2(\psi )d\psi^2 + r\sin(\psi )\cos(\psi )drd\psi\\
  \end{array} 
  \right\}
\end{align}
Grouping similar infinitesimal components and using basic trigonometric identities gives:
\begin{align}
\ ds^2 &= dr^2 +  r^2d\psi^2 + r^2\cos^2(\psi)d\theta^2\\
\text{replace  }\psi\text{ with } \frac{\pi}{2}-\phi \Rightarrow ds^2 &= dr^2 +  r^2d\phi^2 + r^2\sin^2(\phi)d\theta^2\\
\Rightarrow (a_{mn}) &= \begin{pmatrix}
 1& 0 & 0\\
0 & r^2 & 0 \\
0 & 0 & r^2\sin^2(\phi) \\
\end{pmatrix}
\end{align}
\newpage
A more geometrical way of deriving the metric\\
\includegraphics[scale=.6]{sphericalmetric.jpg}\\\\
Consider an infinitesimal displacement of point E to J with $(dr, d\phi , d\theta)$.
\begin{align}
\ ds^2 &= |EJ|^2
\end{align}
As we use infinitesimal displacements we can assume that $$|ES|\perp|GK|\perp|JK|\perp|ES|$$. Hence,
\begin{align}
\ ds^2 = |ES|^2+|SK|^2+|KJ|^2
\end{align}
We have the following relationships
\begin{align}
\left.
\begin{array}{c}
\ |ES| = r\sin(\phi)d\theta\\\\
\ |GE| = |GS| = r\sin(\phi)\\\\
\ |GK| = |RJ| = (r+dr)\sin(\phi+d\phi) \\
\ =(r+dr)(\cos(\phi)\sin(d\phi)+\sin(\phi)\cos(d\phi) )\\
\ = (r+dr)(\cos(\phi)d\phi+\sin(\phi))\\
\ = r\cos(\phi)d\phi+r\sin(\phi)+\sin(\phi)dr\\\\
\ |OR| =  (r+dr)\cos(\phi+d\phi)\\
\ = (r+dr)(\cos(\phi)\cos(d\phi)-\sin(\phi)\sin(d\phi))\\
\ = (r+dr)(\cos(\phi)-\sin(\phi)d\phi)\\
\ = r\cos(\phi)-r\sin(\phi)d\phi + \cos(\phi)dr\\\\
\ |OG| = r\cos(\phi)\\\\
\ |JK| = |OR|-|OG| = \cos(\phi)dr-r\sin(\phi)d\phi\\\\
\ |SK| = |GK|-|GS| = r\cos(\phi)d\phi+\sin(\phi)dr\\\\
\end{array}
\right\}
\end{align}
\begin{align}
\left.
\begin{array}{c}
\ |ES|^2 = r^2\sin^2(\phi)d\theta^2\\
\ |SK|^2 = r^2\cos^2(\phi)d\phi^2+\sin^2(\phi)dr^2 +2r\cos(\phi)\sin(\phi)drd\phi \\
\ |JK|^2 = \cos^2(\phi)dr^2+r^2\sin^2(\phi)d\phi^2 -2r\cos(\phi)\sin(\phi)drd\phi\\
\end{array}
\right\}
\end{align}
Hence,
\begin{align}
\ ds^2 &= |ES|^2+|SK|^2+|KJ|^2\\
&= \left\{ \begin{array}{c} r^2\sin^2(\phi)d\theta^2 \\ +r^2\cos^2(\phi)d\phi^2+\sin^2(\phi)dr^2 +2r\cos(\phi)\sin(\phi)drd\phi\\+r^2\sin^2(\phi)d\phi^2+\cos^2(\phi)dr^2 -2r\cos(\phi)\sin(\phi)drd\phi\\
\end{array}
\right.\\
\ &\Rightarrow ds^2= dr^2 + r^2d\phi^2 + r^2\sin^2(\phi)d\theta^2\\
\ & \Rightarrow (a_{mn}) = \begin{pmatrix}
 1& 0 & 0\\
0 & r^2 & 0 \\
0 & 0 & r^2\sin^2(\phi) \\
\end{pmatrix}
\end{align}
$$\medblackdiamond$$
\newpage


\section{p27-exercise}

\begin{tcolorbox}
Starting from 3.103, show that $$a_{mn} = \pdv{y^1}{x^m}\pdv{y^1}{x^n}+\pdv{y^2}{x^m}\pdv{y^2}{x^n}+\pdv{y^3}{x^m}\pdv{y^3}{x^n}$$ and calculate the quantities for a sphere, taking as curvilinear coordinates on he sphere $$x^1 = y^1 , x^2 = y^2$$
\end{tcolorbox}
We have
\begin{align}
\text{(2.103)}\quad &\Rightarrow y^1 = x^1 , y^2 = x^2, y^3 = f^3(x^1,x^2)\\
\text{surface = sphere}\quad &\Rightarrow y^3 = \pm \sqrt{R^2 -(x^1)^2-(x^2)^2}\\
\ ds^2 &= (dx^1)^2+(dx^2)^2+(dx^3)^2\\
\ \text{(1) and (2)}\quad& \Rightarrow \left\{ \begin{array}{c} 
\ dy^1 = dx^1\\\\
\ dy^2 = dx^2\\\\
\ dy^3 = \pm \frac{1}{2} \frac{-2x^1dx^1 - 2x^2dx^2}{\sqrt{R^2 -(x^1)^2-(x^2)^2}}\\\\
\end{array}
\right.\\
\Rightarrow ds^2 & = (dx^1)^2 +  (dx^2)^2 + \frac{(x^1)^2(dx^1)^2 + (x^2)^2(dx^2)^2  + 2 x^1x^2dx^1dx^2}{R^2 -(x^1)^2-(x^2)^2}
\end{align}
\begin{align}
\Leftrightarrow ds^2 & = \frac{(R^2 - (x^2)^2) (dx^1)^2 + (R^2 -(x^1)^2) (dx^2)^2  + 2 x^1x^2dx^1dx^2}{R^2 -(x^1)^2-(x^2)^2}
\end{align}\\
\begin{align}
\Rightarrow (a_{mn}) &= \frac{1}{R^2 -(x^1)^2-(x^2)^2}\begin{pmatrix}
 R^2 - (x^2)^2&x^1x^2 \\
x^1x^2 & R^2 - (x^1)^2 \\
\end{pmatrix}
\end{align}
$$\medblackdiamond$$
\newpage


\section{p30-clarification 2.202}

\begin{tcolorbox}
           $$\quad\quad a_{mr}\Delta^{ms} = a_{rm}\Delta^{sm} = \delta^s_r a$$
\end{tcolorbox}
Case 1: $r =s$\\
We have, $a_{Rm}\Delta^{Rm}$ (no summation on R) is the definition of the determinant of A developed along the row R: OK.\\\\
Case 2: $r \neq s$\\
Consider
\begin{align}
\ A &= \begin{pmatrix}
 a_{11} & a_{12}&\dots&a_{1N} \\
a_{21} & a_{22}&\dots&a_{2N} \\
\vdots & \vdots &\vdots & \vdots \\
a_{N1} & a_{N2}&\dots&a_{NN} \\
\end{pmatrix}
\end{align}
and consider the matrix $A^,$
\begin{align}
\ A^, &= \begin{pmatrix}
 a_{11} & a_{12}&\dots&a_{1N} \\
 \vdots & \vdots &\vdots & \vdots \\
a_{R1} & a_{R2}&\dots&a_{RN} \\
\vdots & \vdots &\vdots & \vdots \\
a_{R1} & a_{R2}&\dots&a_{RN} \\
\vdots & \vdots &\vdots & \vdots \\
a_{N1} & a_{N2}&\dots&a_{NN} \\
\end{pmatrix}
\begin{array}{c}
\ \vdots\\
\ \vdots\\
\leftarrow S^{th}\text{ row}\\
\vdots\\
\leftarrow R^{th}\text{ row}\\
\ \vdots\\
\ \vdots\\
\end{array}
\end{align}
This matrix corresponds to the way $a_{Rm}\Delta^{Sm}$ is computed. Indeed with the factor $a_{Rm}$ is not associated it's own cofactor $\Delta^{Rm}$ but the cofactor of the $m^{th}$ column in row $S$. Replacing the $S^{th}$ row with the row $R$ and calculating it's determinant is the same as calculating $a_{Rm}\Delta^{Sm}$\\
But, $|A^,| = 0$ as we have two identical rows. So, $a_{Rm}\Delta^{Sm} = 0$\\\\
Conclusion : The same reasoning can be applied when expanding the determinant along the columns instead of the rows we have indeed $\quad\quad a_{mr}\Delta^{ms} = a_{rm}\Delta^{sm} = \delta^s_r a$.
$$\medblackdiamond$$
\newpage


\section{p31-exercise}

\begin{tcolorbox}
Show that if $a{mn} = 0$ for $m\neq n$, then $$a^{11} = \frac{1}{a_{11}}, a^{22} = \frac{1}{a_{22}}, \dots, aÂ¨{12} = 0, \dots$$
\end{tcolorbox}
We have to prove that:
\begin{align}
\ a^{ij} = \left\{\begin{array}{cc}
\frac{1}{a_{ij}} & \text{: }i=j\\
\ 0 & \text{: }i \neq j
\end{array}\right.
\end{align}
From 2.204:
\begin{align}
a_{mR}a_{mS} = \delta^S_R
\end{align}
i) Be $R \neq S$
\begin{align}
\text{(2) }\quad \Rightarrow a_{mR}a_{mS} &= 0\\
\text{but } \quad a_{mR} &=0\quad \forall m \neq R\\
\Rightarrow a_{RR}a^{RS} = 0
\end{align}
but $a_{RR} \neq 0$ ($a_{RR}$ can't be $0$ as the metric tensor would degenerate  if $a_{mn} = 0\quad \forall m \neq n$
\begin{align}
\Rightarrow a^{Rs} = 0\\\\
\end{align}

i) Be $R = S$
\begin{align}
\text{(2) }\quad \Rightarrow a_{mR}a_{mR} &= 1\\
\text{but } \quad a_{mR} &=0\quad \forall m \neq R\\
\Rightarrow a_{RR}a^{RR} = 1\\
\Rightarrow a^{RR} = \frac{1}{a_{RR}}
\end{align}
$$\medblackdiamond$$
\newpage

\section{p31-exercise}

\begin{tcolorbox}
Find the components of $a^{mn}$ for spherical polar coordinates in Eulidean 3-space.
\end{tcolorbox}
We have (see exercise page 27):
\begin{align}
\ (a_{mn}) = \begin{pmatrix}
 1& 0 & 0\\
0 & r^2 & 0 \\
0 & 0 & r^2\sin^2(\phi) \\
\end{pmatrix}
\end{align}
As $a_{mn} = 0 \quad \forall m \neq n$ we deduce (see previous exercise p31)
\begin{align}
\ (a^{mn}) = \begin{pmatrix}
 1& 0 & 0\\
0 & \frac{1}{r^2} & 0 \\
0 & 0 & \frac{1}{r^2\sin^2(\phi)}\\
\end{pmatrix}
\end{align}
$$\medblackdiamond$$
\newpage

\section{p32-exercise}

\begin{tcolorbox}
Find the mixed metric tensor  $a^{.n}_m$ obtained from $a_{mn}$ by raising the second subscript
\end{tcolorbox}
We have :
\begin{align}
\ a_{i}^{.j} &=  a_{in}a^{nj}\\
\ &=  a_{in}a^{jn}\quad a^{jn} \text{  is symmetric}\\
\ &= \delta^j_i \quad \text{ (see 2.205 pg. 30)}\\
\ &\Rightarrow a_{i}^{.j} = \delta^j_i 
\end{align}
$$\medblackdiamond$$
\newpage

\section{p32-clarification 2.214}
\begin{tcolorbox}
          $$ \pdv{a}{a_{mn}} = a a^{mn}$$
\end{tcolorbox}
Put $a_{MN}\equiv a_{mn}$. By definition, we have
\begin{align}
\  a\equiv |a_{mn}|  &= a_{Mk}\Delta^{Mk}\quad\text{(develop determinant along row M)}\\
\ &\Rightarrow \pdv{a}{a_{mn}} = \pdv{a_{Mk}}{a_{mn}}\Delta^{Mk} + a_{Mk}\pdv{\Delta^{Mk}}{a_{mn}}\\
\text{but}\quad &\pdv{a_{Mk}}{a_{mn}} = \left\{\begin{array}{c}
\ 1\quad\text{if} \quad k = N\\
\ 0\quad\text{if} \quad k \neq N\\
\end{array}\right.\\
\text{and}\quad &\pdv{\Delta^{Mk}}{a_{mn}} = 0 \quad \forall k \text{ as } \Delta^{Mk} \text{does not contain the row with } a_{mn} \text{ as element.}\\
\ & \text{(3) and (4)}\quad  \Rightarrow \pdv{a}{a_{mn}} = \Delta^{MN}\\ 
\ &  a^{mn} = \frac{\Delta^{mn}}{a}\quad\text{by definition (see 2.203 page 30)}\\
\ & \Rightarrow \pdv{a}{a_{mn}} = aa^{mn}
\end{align} 
$$\medblackdiamond$$
\newpage


\section{p32-exercise}
\begin{tcolorbox}
Prove that $a_{mn}a^{mn} = N$.
\end{tcolorbox}
From 2.204, we have
\begin{align}
\ a_{mr}a^{ms} &= \delta^s_r\\
\text{Consider} \quad a_{mR}a^{mR} &= 1\\
\text{We can repeat (2) for R = 1,2,...,N} \quad \Rightarrow a_{mr}a^{mr} &= N\\
\end{align}
$$\medblackdiamond$$
\newpage


\section{p33-exercise}
\begin{tcolorbox}
Show that in Euclidean 3-space with rectangular Cartesian coordinates, the definition 2.301 coincides with the usual definition of the magnitude of a vector.
\end{tcolorbox}
The length of an arbitrary vector in Euclidean 3-space with rectangular Cartesian coordinates, is
\begin{align}
\ ds^2 = (dy^1)^2 + (dy^2)^2 (dy^2)^2
\end {align}
From 2.301, it is obvious that the metrixc tensor can be expressed as,
\begin{align}
\begin{pmatrix}1 & 0 &0 \\ 0 & 1 &0\\0 & 0 &1  \\ \end{pmatrix} 
\end{align}
$$\medblackdiamond$$
\newpage


\section{p34-exercise}
\begin{tcolorbox}
A curve in Euclidean 3-space has the equations $$ x^1 =  a \cos(u), x^2 = a\sin(u), x^3 = bu$$ where $x^1, x^2,x^3$ are rectangular Cartesian coordinates,$u$ is a parameter, and $a, b$ are positive constants. Find the length of this curve between the point $u = 0$ and $u = 2\pi$.
\end{tcolorbox}
The metric tensor has the following form,
\begin{align}
\ (a_{ij}) &= \begin{pmatrix}1 & 0 &0 \\ 0 &1 &0\\0 & 0 &1  \\ \end{pmatrix} \\
\text {and  (2.306)  }\quad s &= \int^{2\pi}_0[\epsilon a_{mn}p^mp^n]^{\frac{1}{2}}du
\end{align}
with
\begin{align}
\ p^1 = \dv{x^1}{u} = -a\sin(u), \quad p^2 = \dv{x^2}{u} = a\cos(u), \quad p^3 = \dv{x^3}{u} = b
\end{align}
Hence (2) becomes
\begin{align}
s &= \int^{2\pi}_0\epsilon[a^2 \sin^2(u) + a^2\cos^2(u) + b^2]^{\frac{1}{2}}du\\
\ &= \int^{2\pi}_0\epsilon[a^2+  b^2]^{\frac{1}{2}}du\\
\ &= [a^2+  b^2]^{\frac{1}{2}} \left. u\right|^{2\pi}_0\\
\ &= 2\pi[a^2+  b^2]^{\frac{1}{2}} 
\end{align}
$$\medblackdiamond$$
\newpage

\section{p36-clarification 2.314}
\begin{tcolorbox}
Going from 2.313 to 2.314 yields because both $X^m$ and $Y^m$ are unit vectors and by definition of the magnitude (see 2.301) both  $a_{mn}X^mX^n$ and $a_{mn}Y^mY^n$ are 1 (also due to the fact that only a positive definite metric tensor is considered, $\epsilon = 1$).
\end{tcolorbox}
$$\medblackdiamond$$
\newpage

\section{p37-exercise}

\begin{tcolorbox}
Show that the small angle between unit vectors $X^r$ and $X^r + dX^r$ (these increments being infenitesimal) is given by $$ \theta^2 = a_{mn}X^mX^n$$
\end{tcolorbox}
\begin{figure}[htp] 
    \centering
\includegraphics[scale=.5]{Exp37_1.jpg}
\end{figure}
By definition (2.302 page 33)
\begin{align} 
\ |BC|^2 =\epsilon a_{mn}dX^mdX^n\\
\end{align}
We can drop $\epsilon = 1$ as the considered space is positive definite.\\
As $\theta$ is infinitesimal, we can state
\begin{align}
\ |BC| &\approx |AC|\theta\\
\text{ and } \quad |AC| &= X^r = 1\quad  \text{(as } X^r \text{ is a unit vector)}\\
\Rightarrow \theta^2 &= a_{mn}dX^mdX^n
\end{align}
$$\medblackdiamond$$
\newpage


\section{p39-clarification 2.409}

\begin{tcolorbox}
We clarify the integration by parts in the derivation of the general  geodesic equation.
\end{tcolorbox}
We have 
\begin{align}
\int d(A.B) &= \int AdB + \int BdA\\
\Rightarrow  \int AdB &= \int BdA -  \int d(A.B)\
\end{align}
Now, substitute 2.407 in 2.406, we get
\begin{align}
\dv{L}{v} &= \int \pdv{(\epsilon w)^{\frac{1}{2}}}{x^r} \pdv{x^r}{v} du +  \int \pdv{(\epsilon w)^{\frac{1}{2}}}{p^r} \pdv{p^r}{v} du\\
\ &= \int \pdv{(\epsilon w)^{\frac{1}{2}}}{x^r} \pdv{x^r}{v} du +  \int \pdv{(\epsilon w)^{\frac{1}{2}}}{p^r} \pdv{\pdv{x^r}{v}}{u} du\\
&= \int \pdv{(\epsilon w)^{\frac{1}{2}}}{x^r} \pdv{x^r}{v} du +  \int \pdv{(\epsilon w)^{\frac{1}{2}}}{p^r} d(\pdv{x^r}{v})
\end{align}
To integrate by parts the second term in (5) we put in (2)
$$A= \pdv{(\epsilon w)^{\frac{1}{2}}}{p^r} \quad \text{and } B = \pdv{x^r}{v}$$
\begin{align}
\int \pdv{(\epsilon w)^{\frac{1}{2}}}{p^r} d(\pdv{x^r}{v}) &= \int AdB \\
\ & = \int BdA -  \int d(A.B)\\
\ &= \pdv{(\epsilon w)^{\frac{1}{2}}}{p^r}\left.\pdv{x^r}{v}\right|_{u_0}^{u_1} - \int \pdv{x^r}{v}d(\pdv{(\epsilon w)^{\frac{1}{2}}}{p^r} )\\
\ &= \pdv{(\epsilon w)^{\frac{1}{2}}}{p^r}\left.\pdv{x^r}{v}\right|_{u_0}^{u_1} - \int \pdv{x^r}{v}\pdv{\pdv{(\epsilon w)^{\frac{1}{2}}}{p^r} )}{u}du
\end{align}
Replacing (9) in (5) gives the formulea 2.409.
$$\medblackdiamond$$
\newpage

\section{p41-exercise}
\begin{tcolorbox}
Prove the following identities: $$ [mn,r] = [nm,r], \quad [rm,n]+[rn,m] = \partial_r a_{mn}$$
\end{tcolorbox}
\begin{align}
\ [mn,r] &= \frac{1}{2}(\partial_{n} a_{mr}+ \partial_{m} a_{nr} - \partial_{r} a_{mn})\\
\ &= \frac{1}{2}(\partial_{m} a_{nr} + \partial_{n} a_{mr}  - \partial_{r} a_{nm})\\
\ &=[nm,r] 
\end{align}
and 
\begin{align}
\ [rm,n] + [rn,m]&= \frac{1}{2}(\partial_{r} a_{mn}+ \partial_{m} a_{rn} - \partial_{n} a_{rm} + \partial_{n} a_{rm}+ \partial_{r} a_{mn} - \partial_{m} a_{rn})\\
\ &= \frac{1}{2}(\partial_{r} a_{mn}+\partial_{r} a_{mn})\\
\ &=\partial_{r} a_{mn}
\end{align}
$$\medblackdiamond$$
\newpage

\section{p42-exercise}
\begin{tcolorbox}
Prove that  $$ [mn,r] = a_{rs}\Gamma^s_{mn}$$
\end{tcolorbox}
\begin{align}
\ a_{rs}\Gamma^s_{mn} & = a_{rs}a^{sk}[mn,k]\\
\ & = \delta^k_r[mn,k]\\
\ &= [mn,r]
\end{align}
$$\medblackdiamond$$
\newpage

\section{p42-clarification on 2.430}
\begin{tcolorbox}
... This may proved without difficulty by starting with 2.427, in which $\lambda$ is a known function of $u$ , and defining $s$ by the relation$$ s = \int^u_{u_0}(exp\int^v_{v_0} \lambda(w)dw)dv$$ $u_0, v_0$ being constants....
\end{tcolorbox}
\begin{align}
\text{see 2.428 :} \quad  \lambda (u)=-\frac{\dv[2]{u}{s}}{(\dv{u}{s})^2}\\
\end{align}
We suppose $u(s)$ continuous by parts with continuous inverse.
\begin{align}
\Rightarrow \dv{s}{u} &= \frac{1}{\dv{u}{s}}\\
\Rightarrow \dv[2]{s}{u}&= \dv{(\frac{1}{\dv{u}{s}})}{s}\dv{s}{u}\\
\ & = -\frac{\dv[2]{u}{s}}{(\dv{u}{s})^2}\dv{s}{u}\\
\Rightarrow \frac{\dv[2]{s}{u}}{\dv{s}{u}} &= - \frac{\dv[2]{u}{s}}{(\dv{u}{s})^2}  
\end{align}
By definition (2.428)
\begin{align}
\ \lambda (u) &= - \frac{\dv[2]{u}{s}}{(\dv{u}{s})^2}\\
\text{hence by (6) and (7):}\quad  \lambda (u) &= \frac{\dv[2]{s}{u}}{\dv{s}{u}}\\
\text{in (8) put}\quad y &= \dv{s}{u} \\
\text{ and so} \quad \lambda (w)  &= \frac{y^,}{y}\\
\Rightarrow \int \frac{y^,}{y}dw &= \int \lambda (w)dw\\
\Leftrightarrow \int d(lny) &= \int \lambda (w)dw\\
\Rightarrow \left. ln(y) \right|^v_{v_0} &= \int^v_{v_0} \lambda (w)dw\\
\Rightarrow y  &= exp(\int^v_{v_0} \lambda (w)dw) + C
\end{align}
Taking into account (9), we get:
\begin{align}
\dv{s}{v}  &= exp(\int^v_{v_0} \lambda (w)dw) + C\\
\Rightarrow \left. s \right|^u_{u_0} &=\int^u_{u_0}  exp(\int^v_{v_0} \lambda (w)dw)dv +Cu + B^,\\
\Leftrightarrow  s  &=\int^u_{u_0}  exp(\int^v_{v_0} \lambda (w)dw)dv +Cu + B
\end{align}
We show tha we have to put $C=0$ and can drop the constant $B$. Remember by (8)
\begin{align}
\lambda (u) &= \frac{\dv[2]{s}{u}}{\dv{s}{u}}\\
\text{by (17)} \quad \dv{s}{u}  &=exp(\int^u_{u_0} \lambda (w)dw) +C\\
\text{and}\quad \dv[2]{s}{u}  &= \lambda (u) exp(\int^u_{u_0} \lambda (w)dw) \\
\text{hence by (18), (19) and (20):} \quad \lambda (u)&= \frac{\lambda (u) exp(\int^u_{u_0} \lambda (w)dw)}{exp(\int^u_{u_0} \lambda (w)dw) +C}
\end{align}
So, whatever the constant B, the relation (18) is correct on the condition that C=0. 
So, indeed, we can choose the independent variable $s$ as
$$s  =\int^u_{u_0}  exp(\int^v_{v_0} \lambda (w)dw)dv $$ 
$$\medblackdiamond$$
\newpage

\section{p42-clarification on 2.430}
\begin{tcolorbox}
After 2.430 it is stated:\\
\it{"No matter what values these constants have, 2.424 is satisfied, and by adjusting the constant $v_0$, we can ensure that $a_{mn}\dv{x^m}{s}\dv{x^n}{s} = \pm1$ along $C$, so that $s$ is actually the arc length."}
\end{tcolorbox}
We first prove that 2.4.24 is satisfied, no matter what values the constants take. We have
\begin{align}
\text{(2.430) } \quad  &s =\int_{u_0}^u(exp\int_{v_0}^v \lambda (w)dw)dv\\
\text{and (2.427)} \quad &\dv[2]{x^r}{u} + \Gamma^r_{mn}\dv{x^m}{u}\dv{x^n}{u} =  \lambda \dv{x^r}{u}
\end{align}
In (2) we can write the first term as
\begin{align}
\quad \dv[2]{x^r}{u} &= \dv{(\dv{x^r}{u})}{s}\dv{s}{u} \\
\text{with } \quad \dv{(\dv{x^r}{u})}{s} &=  \dv{(\dv{x^r}{s}\dv{s}{u})}{s} = \dv[2]{x^r}{s}\dv{s}{u}+\dv{x^r}{s}\dv{(\dv{s}{u})}{s} 
\end{align}
Assuming the curve smooth, we have
\begin{align}
\dv{(\dv{s}{u})}{s} & = \dv{(\frac{1}{\dv{u}{s}})}{s} = -\frac{\dv[2]{u}{s}}{(\dv{u}{s})^2}= \lambda
\end{align}
Putting (4) and (5) in (3) we get
\begin{align}
\dv[2]{x^r}{u} &= \dv[2]{x^r}{s} \left ( \dv{s}{u}\right )^2 + \lambda\dv{x^r}{s}\dv{s}{u}
\end{align}
Plugging (6) in 2.427 gives:
\begin{align}
\dv[2]{x^r}{s} \left (\dv{s}{u}\right )^2 + \lambda\dv{x^r}{s}\dv{s}{u} +\Gamma^r_{mn}\dv{x^m}{s}\dv{x^n}{s}\left (\dv{s}{u}\right )^2  &=  \lambda \dv{x^r}{s}\dv{s}{u}\\
\Leftrightarrow \dv[2]{x^r}{s} \left (\dv{s}{u}\right )^2 +\Gamma^r_{mn}\dv{x^m}{s}\dv{x^n}{s}\left (\dv{s}{u}\right )^2  &=  0
\end{align}
We can assume that $\dv{s}{u} $ does not become $0$ or $\pm \infty$ along the curve by choosing an adequate constant $v_0$. Indeed, from (2.430) we get
\begin{align}
\dv{s}{u}  &= exp(\int_{u_0}^u \lambda (w)dw)\\
\ &= \frac{\phi (u)}{\phi (u_0)}
\end{align}
with $\phi (u_0) =  e^{\theta(u_0)}$, $\theta(u)$ being the indefinite integral $\int \lambda (w)dw $.\\
So, it is sufficient to choose $v_0$ so that $\theta(u_0)$ does not become  $\pm \infty$ to ensure that $\dv{s}{u} \ne 0$ or $ \ne \pm \infty$ along the curve and so we have from (8)
\begin{align}
\dv[2]{x^r}{s} +\Gamma^r_{mn}\dv{x^m}{s}\dv{x^n}{s}  &=  0\end{align}
which is the definition (2.424) of a geodesic.\\\\
The same reasoning about $\dv{s}{u} \ne 0$ can be made to prove that $a_{mn}\dv{x^m}{s}\dv{x^n}{s} = \pm1$ along $C$. Indeed, by definition (2.305):
\begin{align}
\ ds = &\left[ \epsilon a_{mn}\dv{x^m}{u}\dv{x^n}{u}\right]^\frac{1}{2}\\
\text{ equating with (9)} \quad   &\left[ \epsilon a_{mn}\dv{x^m}{u}\dv{x^n}{u}\right]^\frac{1}{2} =                 exp(\int_{u_0}^u \lambda (w)dw)\\
\Rightarrow \quad &\epsilon a_{mn}\dv{x^m}{s}\dv{x^n}{s}\left (\dv{s}{u}\right )^2 =  \left[ exp(\int_{u_0}^u \lambda (w)dw) \right]^2\\
\text{but} \quad &\dv{s}{u} = exp(\int_{u_0}^u \lambda (w)dw)\\
\text{ and so, (9) becomes} \quad &\epsilon a_{mn}\dv{x^m}{s}\dv{x^n}{s}\left (\dv{s}{u}\right )^2 =  \left (\dv{s}{u}\right )^2\\
\Rightarrow \quad & a_{mn}\dv{x^m}{s}\dv{x^n}{s}=\epsilon
\end{align}
$$\medblackdiamond$$
\newpage


\section{p43-clarification }
\begin{tcolorbox}
$$\lambda = \Gamma^N_{\mu \nu}\dv{x^{\mu}}{x^N} \dv{x^{\nu}}{x^N} + 2\Gamma^N_{\mu N}\dv{x^{\mu}}{x^N}+\Gamma^N_{N N} $$
\end{tcolorbox}
We start with 2.427 with $r=N$
\begin{align}
\ &\dv[2]{x^N}{{x^{N}}} + \Gamma^N_{\mu\nu}\dv{x^{\mu}}{x^N} \dv{x^{\nu}}{x^N} = \lambda \dv{x^N}{x^N}\\
\Rightarrow\quad &\Gamma^N_{\mu\nu}\dv{x^{\mu}}{x^N} \dv{x^{\nu}}{x^N} = \lambda \quad \text{(as}\quad \dv[2]{x^N}{{x^{N}}} = 0 \quad \dv{x^N}{x^N} = 1 \text{)}
\end{align}
But (2) is only valid with the dummy indices $\mu$ and $\nu$ spanning the whole dimension $(1,2,\dots N)$, but by choice $\mu,\nu \quad \epsilon \quad (1,2, \dots, N-1)$. We have thus to add in the left term of (2) the cases
\begin{align}
\left\{ \begin{array}{cc}
\Gamma^N_{N\nu}& \nu = (1,2,\dots ,N-1)\\\\
\Gamma^N_{\mu N}& \mu = (1,2,\dots ,N-1)\\\\
\Gamma^N_{NN}& \\
\end{array} \right.\\
\text{(2) becomes } \quad \Gamma^N_{\mu\nu}\dv{x^{\mu}}{x^N} \dv{x^{\nu}}{x^N} + \Gamma^N_{N \nu}\dv{x^N}{x^N} \dv{x^{\nu}}{x^N} + \Gamma^N_{\mu N}\dv{x^{\mu}}{x^N} \dv{x^{N}}{x^N} + \Gamma^N_{NN}\dv{x^{N}}{x^N} \dv{x^{N}}{x^N}= \lambda\\
\Rightarrow   \quad \Gamma^N_{\mu\nu}\dv{x^{\mu}}{x^N} \dv{x^{\nu}}{x^N} + \Gamma^N_{N \nu}\dv{x^{\nu}}{x^N} + \Gamma^N_{\mu N}\dv{x^{\mu}}{x^N}+ \Gamma^N_{NN} = \lambda
\end{align}
As $\Gamma^N_{\mu N}$ is symmetric on the lower indices and $\mu$, $\nu$ being dummy indices:
\begin{align}
\lambda  =\Gamma^N_{\mu\nu}\dv{x^{\mu}}{x^N} \dv{x^{\nu}}{x^N} + 2\Gamma^N_{N \nu}\dv{x^{\nu}}{x^N} +\Gamma^N_{NN}
\end{align}
The other $N-1$ equation for $r= 1,\dots, N-1$ can be deduced following the same reasoning.
$$\medblackdiamond$$
\newpage


\section{p45-clarification }
\begin{tcolorbox}
$ f_r \equiv a_{rm}\dv[2]{x^m}{u} +[mn,r]\dv{x^m}{u}\dv{x^n}{u}$ is covariant and 
$ f^r \equiv \dv[2]{x^m}{u} +\Gamma^r_{mn}\dv{x^m}{u}\dv{x^n}{u}$ is contravariant.
\end{tcolorbox}
\begin{align}
\ &f_r \equiv a_{rm}\dv[2]{x^m}{u} +[mn,r]\dv{x^m}{u}\dv{x^n}{u}\\
\text{multiply with}\quad a^{sr}\quad \Rightarrow\quad &f_r a^{sr} = a^{sr}a_{rm}\dv[2]{x^m}{u} +a^{sr}[mn,r]\dv{x^m}{u}\dv{x^n}{u}\\
\Rightarrow\quad &f^{s} = \delta^s_m \dv[2]{x^m}{u} +\underbrace{a^{sr}[mn,r]}_{\Gamma^s_{mn}}\dv{x^m}{u}\dv{x^n}{u}\\
\Rightarrow \quad &f^{s} = \dv[2]{x^s}{u} +\Gamma^s_{mn}\dv{x^m}{u}\dv{x^n}{u}
\end{align}
By lifting the index of $f_r$ we get a contravariant vector confirming that (4) is contravariant.
$$\medblackdiamond$$
\newpage

\section{p45-clarification }
\begin{tcolorbox}
(2.443) and (2.444)
$$ p^r\pdv{w}{p^r} - w = C^t \quad \Rightarrow\quad w = C^t $$ 
\end{tcolorbox}
By definition 
\begin{align}
\ w &= a_{mn}p^mp^n\\
\Rightarrow\quad \pdv{w}{p^r} &= a_{mn}(\pdv{p^m}{p^r}p^n + p^m \pdv{p^n}{p^r})\\
\ &= a_{mn}(\delta^m_rp^n + p^m \delta^n_r)\\
\ &= a_{rn}p^n + a_{mr}p^m \\
\ &= 2a_{mr}p^m \quad\text{(as } a_{mn} \quad \text{is symmetric)}\\
\text{(4)}\quad \Rightarrow \quad p^r\pdv{w}{p^r} &= 2a_{mr}p^rp^m \\
\ &= 2w\\
\text{(2.443)} \quad\Rightarrow\quad p^r\pdv{w}{p^r} -w &= 2w-w = w = C^t\\
\Rightarrow\quad w &\equiv a_{mn}p^mp^n = C^t
\end{align}
$$\medblackdiamond$$
\newpage

\section{p46-"geodesic null lines", some personal thoughts}
\begin{tcolorbox}
Can we grasp intuitively the notion of "geodesic null lines"? To understand this, here are two example of "geodesic null lines"
\end{tcolorbox}
We consider two examples, a classic one (Minkowski space) and a weird space.\\\\
i) on dimensional Minkowski space\\\\
For this space the metric is in normalized coordinates $$ ds^2 = dx^2 - dt^2$$
It is easy to see that the equations of a geodesic null line (taking $t$ as parameter for the curve), reduce to \\
\begin{align}
\left. \begin{array}{c}
\dv[2]{x}{t} = 0\\\\
\ dx^2-dt^2 = 0
\end{array} \right \}\\
\Rightarrow x = at+b \quad \text{ and } \quad x = \pm t + g
\end{align}
If we choose $x=t$ at $t=0$ we see that the geodesic null lines are the bisectors of the x-t axes.\\\\
ii) We consider a $V_2$ space equipped with a polar coordinate system and with a metric tensor defined as 
\begin{align}
\ ds^2 = (1-r)dr^2 + \sin(\theta)d \theta ^2
\end{align}
Giving as geodesic null line equations
\begin{align}
\left. \begin{array}{c}
\dv[2]{r}{u} +\frac{1}{2(r-1)}(\dv{r}{u})^2 = 0\\\\
\dv[2]{\theta}{u} +\frac{1}{2}\cot(\theta)(\dv{\theta}{u})^2 = 0\\\\
\ (1-r)(\dv{r}{u})^2+ \sin(\theta)(\dv{\theta}{u})^2 = 0
\end{array} \right \}
\end{align}
We see immediately that for $r \rightarrow 1$ and $ \theta\rightarrow k\frac{\pi}{2} \quad (k= 0, \pm 1, \pm2, \dots)$, some problems will occur and that no solutions might be found. On the next page some geodesic null lines are showed (equations solved numerically with Python Scipy library)
\newpage
\begin{figure}[htp] 
    \centering
\includegraphics[scale=.2]{nullgeodesics_theta.jpg}
\includegraphics[scale=.25]{nullgeodesics_R.jpg}
\includegraphics[scale=.25]{nullgeodesics_theta_p.jpg}
\end{figure}
The first row shows the results for points at 2 different distance from the origin while changing the angle $\theta$. \\
The second row shows the results for points at 2 different angles  while changing the distance from the origin. \\
The second row shows the results for  a specific point while changing the the $\dv{\theta}{u}$ value in the initial condition when solving the system of differential equations. \\
Conclusion: with non-trivial metrics, getting an intuitive idea about the geodesic null lines gets very hard.
$$\medblackdiamond$$
\newpage

\section{p47-exercise }
\begin{tcolorbox}
The class of all parameters $u$, for which the equations of a geodesic null line assume the simple form 2.445, are obtained from any one such parameter by linear transformation $$ \overline{u} = au + b$$ $a$ and $b$ being constants.
\end{tcolorbox}
The simple form 2.445 is :
\begin{align}
\  \dv[2]{x^r}{u} +\Gamma^r_{mn}\dv{x^m}{u}\dv{x^n}{u} = 0\\
\end{align}
The general form of a geodesic is (2.447) 
\begin{align}
\  \dv[2]{x^r}{\overline{u}} +\Gamma^r_{mn}\dv{x^m}{\overline{u}}\dv{x^n}{\overline{u}} = \lambda \dv{x^r}{\overline{u}}\\
\end{align}
So (2.447) can only of the form (2.445) if $\lambda = 0$
\begin{align}
\   \lambda  = - \frac{\dv[2]{\overline{u}}{u}}{\left( \dv{\overline{u}}{u}\right)^2} = 0\\
\end{align}
We can state that $\dv{\overline{u}}{u}\ne 0$ as $\overline{u}$ can't be a constant (being a parameter of a curve). So,
\begin{align}
\dv[2]{\overline{u}}{u}&=0\\
\Rightarrow \quad \dv{\overline{u}}{u}&=a\\
\Rightarrow \quad \overline{u}&=au +b
\end{align}
$$\medblackdiamond$$
\newpage


\section{p47-exercise }
\begin{tcolorbox}
Consider a 3-space with coordinates $x,y,z$ and a metric form $\Phi = (dx)^2+(dy)^2 - (dz)^2$. prove that the geodesic null lines may be represented by the equations
$$x = au + a^,\quad y = bu + b^, \quad z = cu + c^,$$
where $u$ is a parameter and $a, a^,,b,b^,,c,c^,$ are constants which are arbitrary except for the relation $a^2+b^2-c^2 =0$.
\end{tcolorbox}
Given is 
\begin{align}
\Phi = (dx)^2+(dy)^2 - (dz)^2
\end{align}
From the previous exercise we have already proven that $x,y,z$ are of the form
\begin{align}
\ x^i = q_i u + q_i^,
\end{align}
To be a null geodesic null line we need to have (2.448)
\begin{align}
\ a_{mn}\dv{x^m}{u}\dv{x^n}{u} &=0\\
\text{from (1) we deduce}  \quad (a_{mn}) &= \begin{pmatrix}
1& 0 & 0 \\
 0&1  & 0 \\
 0&  0& -1 \\
\end{pmatrix}\\
\text{(3)}\quad\Rightarrow\quad (dx)^2+(dy)^2 - (dz)^2 &=0\\
\text{(2)}\quad\Rightarrow\quad (q_1)^2+(q_2)^2 - (q_3)^2 &=0
\end{align}
$$\medblackdiamond$$
\newpage

\section{p48-exercise }
\begin{tcolorbox}
Prove that the Christoffel symbols of the first kind transform according the equation 
$$[mn,r]^, =  [pq,s]\pdv{x^p}{x^{,m}} \pdv{x^q}{x^{,n}}\pdv{x^s}{x^{,r}}+ a_{pq}\pdv{x^p}{x^{,r}}\pdv{x^q}{x^{,m}}{x^{,n}}$$
\end{tcolorbox}
From 2.438 page 45, we have
\begin{align}
\ f_r &\equiv a_{rm}\dv[2]{x^m}{u} +[mn,r]\dv{x^m}{u}\dv{x^n}{u} \quad\text{is covariant} \\
\Rightarrow\quad f_r^, &= f_s\pdv{x^s}{x^{,r}}\\
\text{with}\quad f_r^, &= a^,_{rm}\dv[2]{x^{,m}}{u} +[mn,r]^, \dv{x^{,m}}{u}\dv{x^{,n}}{u}
\end{align}
Combining (1), (2) and (3) gives 
\begin{align}
\ a^,_{rm}\dv[2]{x^{,m}}{u} +[mn,r]^, \dv{x^{,m}}{u}\dv{x^{,n}}{u} = ( a_{sm}\dv[2]{x^m}{u} +[mn,s]\dv{x^m}{u}\dv{x^n}{u})\pdv{x^s}{x^{,r}}
\end{align}
We rewrite (4) as 
\begin{align}
\ [mn,r]^, \dv{x^{,m}}{u}\dv{x^{,n}}{u} &= -\underbrace{a^,_{rm}\dv[2]{x^{,m}}{u}}_\text{(*)} +\underbrace{ a_{sm}\dv[2]{x^m}{u}\pdv{x^s}{x^{,r}}}_\text{(**)} +\underbrace{[mn,s]\dv{x^m}{u}\dv{x^n}{u}\pdv{x^s}{x^{,r}}}_\text{(***)}\\
\text{(***)} &\Leftrightarrow [mn,s]\pdv{x^m}{x^{,p}}\dv{x^{,p}}{u}\pdv{x^n}{x^{,q}}\dv{x^{,q}}{u}\pdv{x^s}{x^{,r}}
\end{align}
In (6) renaming the dummy indices $m,n,p,q$ gives
\begin{align}
\text{(***)} &\Leftrightarrow [pq,s]\pdv{x^p}{x^{,m}}\dv{x^{,m}}{u}\pdv{x^q}{x^{,n}}\dv{x^{,n}}{u}\pdv{x^s}{x^{,r}}\\
&\Leftrightarrow [pq,s]\pdv{x^p}{x^{,m}}\pdv{x^q}{x^{,n}}\pdv{x^s}{x^{,r}}\left(\dv{x^{,m}}{u}\dv{x^{,n}}{u}\right)
\end{align}
Also,
\begin{align}
\text{(**)} &\Leftrightarrow  a_{sm}\dv[2]{x^m}{u}\pdv{x^s}{x^{,r}}\\
\text{As we have also}\quad \dv[2]{x^m}{u} &= \dv{(\pdv{x^m}{x^{,p}}\dv{x^{,p}}{u})}{u}\\
&= \pdv{x^m}{x^{,p}}\dv[2]{x^{,p}}{u}+\dv{x^{,p}}{u}\pdv{x^m}{x^{,p}}{x^{,q}}\dv{x^{,q}}{u} 
\end{align}
(11) and (9) gives by changing the dummy indices ( $m\rightarrow t$, $p\rightarrow m$, $q\rightarrow n$)
\begin{align}
\text{(**)}&= \underbrace{a_{st}\pdv{x^t}{x^{,p}}\dv[2]{x^{,p}}{u}\pdv{x^s}{x^{,r}}}_\text{(****)}+a_{pq}\pdv{x^q}{x^{,m}}{x^{,n}}\pdv{x^{p}}{x^{,r}}\left(\dv{x^{,m}}{u}\dv{x^{,m}}{u}\right) \\
\text{with (****)}\quad &= a_{st}\left(\pdv{x^t}{x^{,m}}\pdv{x^s}{x^{,r}}\right)\dv[2]{x^{,m}}{u}
\end{align}
But $a_{st}$  is a covariant tensor, so
\begin{align}
\ a^{,}_{rm} &= a_{st}\pdv{x^t}{x^{,m}}\pdv{x^s}{x^{,r}}\\
\text{(13) becomes}\quad \text{(****)} &= a^{,}_{rm}\dv[2]{x^{,m}}{u}\\
\text{and from (5) we have }\quad \text{(*)} &= -a^{,}_{rm}\dv[2]{x^{,m}}{u}\\
\end{align}
and both terms cancel each other in equation (5). So adding $(*), (**)$ and $(***)$ in (5) , we get 
\begin{align}
\ [mn,r]^, \dv{x^{,m}}{u}\dv{x^{,n}}{u} &= a_{pq}\pdv{x^q}{x^{,m}}{x^{,n}}\pdv{x^{p}}{x^{,r}}\left(\dv{x^{,m}}{u}\dv{x^{,m}}{u}\right)+[pq,s]\pdv{x^p}{x^{,m}}\pdv{x^q}{x^{,n}}\pdv{x^s}{x^{,r}}\left(\dv{x^{,m}}{u}\dv{x^{,n}}{u}\right)\\
\Rightarrow \ &[mn,r]^, =[pq,s]\pdv{x^p}{x^{,m}}\pdv{x^q}{x^{,n}}\pdv{x^s}{x^{,r}}+  a_{pq}\pdv{x^{p}}{x^{,r}}\pdv{x^q}{x^{,m}}{x^{,n}}
\end{align}
$$\medblackdiamond$$
\newpage

\section{p50-clarification 2.515 }
\begin{tcolorbox}
$$\dv{\left(T_rS^r\right)}{u} = \dv{T_r}{u}S^r + T_r\dv{S^r}{u} = \left(\dv{T_r}{u} - \Gamma^m_{rn}T_m\dv{x^n}{u}\right)S^r$$ with $$\frac{\delta T_r}{\delta u} = \dv{T_r}{u} -\Gamma^m_{rn}\dv{x^n}{u} T_m$$ a covariant vector.
\end{tcolorbox}
It is given that $S^r$ is a tensor propagated parallelly along the curve. The by (2.5212) we have
\begin{align}
\dv{S^r}{u} &+ \Gamma^r_{mn}S^m\dv{x^n}{u}= 0\\
\dv{S^r}{u} &= - \Gamma^r_{mn}S^m\dv{x^n}{u}\\
\text{and}\quad \dv{\left(T_rS^r\right)}{u} &= \dv{T_r}{u}S^r + T_r\dv{S^r}{u} \\
\ &= \dv{T_r}{u}S^r -\Gamma^r_{mn}S^m\dv{x^n}{u} T_r\\
\end{align}
Swap dummy indices $r$ and $m$ in the second term:
\begin{align}
\dv{\left(T_rS^r\right)}{u} &= \dv{T_r}{u}S^r -\Gamma^m_{rn}S^r\dv{x^n}{u} T_m\\
\ &= \left(\dv{T_r}{u} -\Gamma^m_{rn}\dv{x^n}{u} T_m\right)S^r\\
\end{align}
As $T_rS^r$ is an invariant and thus is also $\dv{\left(T_rS^r\right)}{u}$ and as $S^r$ can be chosen arbitrarily (as long it is a contravariant tensor), implies that $$\dv{T_r}{u} -\Gamma^m_{rn}\dv{x^n}{u} T_m$$ is covariant and thus also $$\frac{\delta T_r}{\delta u} = \dv{T_r}{u} -\Gamma^m_{rn}\dv{x^n}{u} T_m$$
$$\medblackdiamond$$
\newpage

\section{p50-clarification 2.516}
\begin{tcolorbox}
$$\frac{\delta T_{rs}}{\delta u} \equiv \dv{T_{rs}}{u}  - \Gamma^m_{rn}T_{ms}\dv{x^n}{u} - \Gamma^m_{sn}T_{rm}\dv{x^n}{u}$$ is a covariant vector.
\end{tcolorbox}
We build an invariant $ T_{rs} S^rU^s$ with $S^r$ and $U^s$ arbitrary contravariant tensors. The we know that $\dv{\left( T_{rs} S^r U^s\right)}{u}$ is also an invariant. We have 
\begin{align}
\dv{\left( T_{rs} S^r U^s\right)}{u} = \dv{T_{rs}}{u} S^r U^s + T_{rs} \dv{S^r}{u} U^s + T_{rs} S^r \dv{U^s}{u}
\end{align} 
with with $S^r$ and $U^s$ propagated parallelly along the curve. Then,
\begin{align}
\dv{S^r}{u} = - \Gamma^r_{mn}S^m\dv{x^n}{u}\\
\dv{U^s}{u} = - \Gamma^s_{mn}Y^m\dv{x^n}{u}
\end{align} 
(2), (3) in (1) gives 
\begin{align}
\dv{\left( T_{rs} S^r U^s\right)}{u} = \dv{T_{rs}}{u} S^r U^s - T_{rs}U^s\Gamma^r_{mn}S^m\dv{x^n}{u} - T_{rs} S^r \Gamma^s_{mn}U^m\dv{x^n}{u}
\end{align} 
Changing the dummy indices in the second and third term gives:
\begin{align}
\dv{\left( T_{rs} S^r U^s\right)}{u} = (\dv{T_{rs}}{u}  - \Gamma^m_{rn}T_{ms}\dv{x^n}{u} - \Gamma^m_{sn}T_{rm}\dv{x^n}{u})S^r U^s
\end{align} 
As the left term is an invariant and $S^r$ and $U^s$ are arbitrary contravariant tensors, means that the expression in the brackets in the right part of the equation, is a covariant tensor.
$$\medblackdiamond$$
\newpage

\section{p51-exercise}
\begin{tcolorbox}
Find the absolute derivative of $T^r_{st}$.
\end{tcolorbox}
Define the invariant $ I = D^r_{st}R^rS_sT_t$ 
\begin{align}
\ I &= D^r_{st}R^rS_sT_t\\
\Rightarrow A &= \dv{I}{u}= 
\dv{\left(D^r_{st}\right)}{u}R^rS_sT_t+
\ D^r_{st}S_sT_t\dv{\left(R^r\right)}{u}+
\ D^r_{st}R_rT_t\dv{\left(S^s\right)}{u}+
\ D^r_{st}R_rS_s\dv{\left(T^t\right)}{u}
\end{align} 
Reminder, performing a parallel propagation of a covariant and contravariant vector gives as equations
\begin{align}
\dv{V^v}{u} = - \Gamma^v_{mn}V^m\dv{x^n}{u}\\
\dv{W_w}{u} = + \Gamma^m_{wn}W^m\dv{x^n}{u}
\end{align}
So (2) becomes:
\begin{align}
\ A = \left\{ \begin{array}{c}
\dv{\left(D^r_{st}\right)}{u}R^rS_sT_t\\\\
\ -D^r_{st}S_sT_t\Gamma^r_{mn}R^m\dv{x^n}{u}\\\\
\ +D^r_{st}R_rT_t \Gamma^m_{sn}S^m\dv{x^n}{u}\\\\
\ +D^r_{st}R_rS_s\Gamma^m_{tn}T^m\dv{x^n}{u}
\end{array} \right.
\end{align}
In (5) apply the following renaming of dummy variables 
$$\left\{\begin{array}{c}
2^{nd} line: \quad r\rightarrow m, m \rightarrow r\\
3^{rd} line: \quad s\rightarrow m, m \rightarrow s\\
4^{th} line: \quad t\rightarrow m, m \rightarrow t\\
\end{array}  \right. $$
and regrouping terms with $R^rS_sT_t$,(5) becomes then
\begin{align}
\ A = \left[\dv{\left(D^r_{st}\right)}{u}+(\ D^r_{mt}\Gamma^s_{mn}+\ D^r_{sm}\Gamma^t_{mn}-\ D^m_{st}\Gamma^m_{rn})\dv{x^n}{u}\right]R^rS_sT_t
\end{align}
But $A$ is an invariant, so the expression in the square parenthesis is a tensor of the form $T^r_{st}$ and we define the absolute derivative of $T^r_{st}$ as:
$$ \frac{\delta T^r_{st}}{\delta u} = \dv{\left(T^r_{st}\right)}{u}+\Gamma^s_{mn} T^r_{mt}\dv{x^n}{u}+\Gamma^t_{mn}T^r_{sm}\dv{x^n}{u}-\Gamma^m_{rn} T^m_{st}\dv{x^n}{u}$$
$$\medblackdiamond$$
\newpage

\section{p53-exercise}
\begin{tcolorbox}
Prove that $$\delta^r_{s|t} = 0, \quad a^{rs}_{|t} = 0$$
\end{tcolorbox}

i)$\delta^t_{s|t} = 0$
\begin{align}
\text{(2.524) gives:}\quad \delta^r_{s|t} &= \underbrace{\pdv{\delta^r_{s}}{x^t}}_\text{=0} + \Gamma^r_{mt}\delta^m_{s}- \Gamma^m_{st}\delta^r_{m}\\
&= \Gamma^r_{st}- \Gamma^r_{st} = 0
\end{align}

ii)$ a^{rs}_{|t} = 0$
We know that 
\begin{align}
\delta^r_{s|t} &= a_{sk}a^{kr}|_{t}\\
\Rightarrow \delta^r_{s|t} &= \pdv{a_{sk}}{x^t}a^{kr}+ a_{sk}\pdv{a^{kr} }{x^t} + \Gamma^r_{mt}a_{sk}a^{km}- \Gamma^m_{st}a_{mk}a^{kr}
\end{align}
Rearrange (4) and add $\Gamma^k_{mt}a_{ks}a^{mr}$ and subtract $\Gamma^m_{kt}a_{ms}a^{kr}$ (as $\Gamma^k_{mt}a_{ks}a^{mr} - \Gamma^m_{kt}a_{ms}a^{kr}  =0 $)
\begin{align}
\delta^r_{s|t} &= (\pdv{a_{sk}}{x^t}- \Gamma^m_{st}a_{mk}-\Gamma^m_{kt}a_{ms} )a^{kr}+ (\pdv{a^{kr} }{x^t} + \Gamma^r_{mt}a^{km}+ \Gamma^k_{mt}a^{mr})a_{sk}\\
\text{but} \quad  a_{sk|t} &= (\pdv{a_{sk}}{x^t}- \Gamma^m_{st}a_{mk}-\Gamma^m_{kt}a_{ms})\\
\text{and as (2.526)}\quad a_{sk|t} = 0\\
\text{(5) becomes}\quad \delta^r_{s|t} &= \underbrace{(\pdv{a^{kr} }{x^t} + \Gamma^r_{mt}a^{km}+ \Gamma^k_{mt}a^{mr})}_{\begin{huge}a^{kr}_{|t}\end{huge}}a_{sk}\\
\ &= a^{kr}_{|t}a_{sk}\\
\ &= 0 \quad \text{as}\quad \delta^r_{s|t}=0  \quad \text{(see first  part of this exercise)}
\end{align}
As all $a_{ks}$ can't be zero and as we didn't choose any special Riemannian space, we can conclude from $ a^{kr}_{|t}a_{sk} = 0$ that $$ a^{rs}_{|t} = 0$$ 
$$\medblackdiamond$$
\newpage

\section{p54-exercise}
\begin{tcolorbox}
Prove that $$\dv{(a_{mn}\lambda^m\lambda^n)}{s} = 2 a_{mn}\lambda^m \frac{\delta\lambda^n}{\delta s}$$
\end{tcolorbox}
\begin{align} \dv{(a_{mn}\lambda^m\lambda^n)}{s}= \dv{a_{mn}}{s}\lambda^m\lambda^n+2a_{mn}\lambda^m \dv{\lambda^n}{s}
\end{align}
By definition of the absolute derivative, we have:
\begin{align}
\frac{\delta \lambda^n}{\delta s}& =\dv{\lambda ^n}{s}  + \Gamma^n_{pk}\lambda^p\dv{x^k}{s} \\
\text{(2) in (1)}\quad \dv{(a_{mn}\lambda^m\lambda^n)}{s}&= \dv{a_{mn}}{s}\lambda^m\lambda^n+2a_{mn}\lambda^m (\frac{\delta \lambda^n}{\delta s} - \Gamma^n_{pk}\lambda^p\dv{x^k}{s})\\
\ &= \dv{a_{mn}}{s}\lambda^m\lambda^n+2a_{mn}\lambda^m \frac{\delta \lambda^n}{\delta s} - 2a_{mn}\lambda^m \Gamma^n_{pk}\lambda^p\dv{x^k}{s}\\
\text{we have} \quad \Gamma^n_{pk} &= a^{ns}[pk,s]\\
\text{so,} \quad \dv{(a_{mn}\lambda^m\lambda^n)}{s}&= \dv{a_{mn}}{s}\lambda^m\lambda^n+2a_{mn}\lambda^m \frac{\delta \lambda^n}{\delta s} - 2\underbrace{a_{mn}a^{ns}}_{=\delta^s_m}[pk,s]\lambda^m \lambda^p\dv{x^k}{s}\\
&= \dv{a_{mn}}{s}\lambda^m\lambda^n+2a_{mn}\lambda^m \frac{\delta \lambda^n}{\delta s} - 2[pk,m]\lambda^m \lambda^p\dv{x^k}{s}\\
\text{but} \quad 2[pk,m]\lambda^m\lambda^p &= [pk,m]\lambda^m\lambda^p+[pk,m]\lambda^m\lambda^p\\
&= [pk,m]\lambda^m\lambda^p+[mk,p]\lambda^m\lambda^p\\
\text{we have also }\quad &\left \{ \begin{array}{c}
\ [pk,m] = \frac{1}{2}(\partial _k a_{pm} + \partial _p a_{km}-\partial _m a_{pk})\\
\ [mk,p] = \frac{1}{2}(\partial _k a_{pm} + \partial _m a_{pk}-\partial _p a_{mk})\\
\end{array}\right.\\
\ &\Rightarrow 2[pk,m] = \partial _k a_{pm}\\
\text{so} \quad \dv{(a_{mn}\lambda^m\lambda^n)}{s} &= \dv{a_{mn}}{s}\lambda^m\lambda^n - \underbrace{ \partial _k a_{pm}\dv{x^k}{s}}_{=\dv{a_{mn}}{s}} \lambda^m \lambda^p +2a_{mn}\lambda^m \frac{\delta \lambda^n}{\delta s} \\
\ & \Rightarrow \quad  \dv{(a_{mn}\lambda^m\lambda^n)}{s} = 2a_{mn}\lambda^m \frac{\delta \lambda^n}{\delta s} 
\end{align} 
$$\medblackdiamond$$
\newpage

\section{p54-exercise}
\begin{tcolorbox}
Prove that $$(T^rS_s)_{|n} = T^r_{|n}S_s+T^rS_{|n}$$
\end{tcolorbox}
\begin{align} (T^rS_s)_{|n} &=  \partial_n(T^rS_s) + \Gamma^r_{nm}T^mS_s - \Gamma^m_{sn}T^rS_m\\
\ &=  \partial_n(T^r)S_s+ T^r\partial_n(S_s) + S_s\Gamma^r_{nm}T^m - T^r\Gamma^m_{sn}S_m\\
\ &=  T^r\underbrace{(\partial_n(S_s) - \Gamma^m_{sn}S_m)}_{S_{s|n}}+S_s\underbrace{(\partial_n(T^r)+ \Gamma^r_{nm}T^m)}_{T^r_{|n}}\\
\ &=  T^rS_{s|n}+S_sT^r_{|n}
\end{align}
$$\medblackdiamond$$
\newpage

\section{p57-exercise}
\begin{tcolorbox}
Compute the Christoffel symbols in 2.540 directly from the definitions 2.421 and 2.422. Check that all Christoffels symbols not shown explicitly in 2.540 vanish.
\end{tcolorbox}
\textit{Easy but very tedious, not reproduced yet, later perhaps}
$$\medblackdiamond$$
\newpage

\section{p57-exercise}
\begin{tcolorbox}
Show that for the spherical polar metric 2.532, we have $ln\sqrt{a} = 2 ln(x^1)+ln(sin(x^2))$ and 
$$\textbf{2.544}\quad \Gamma^n_{1n} = \frac{2}{x^1},\quad \Gamma^n_{2n} = \cot (x^2),\quad\Gamma^n_{3n} =0$$
\end{tcolorbox}
The spherical polar metric 2.532 is,
\begin{align}
\ (a_{mn})&= \begin{pmatrix}
 1& 0 & 0 \\
 0& (x^1)^2 & 0 \\
 0& 0 & (x^1 \sin (x^2))^2 \\
\end{pmatrix}\\
\Rightarrow |a_{mn}| &= \left[(x^1)^2 \sin (x^2)\right]^2\\
\Rightarrow ln(\sqrt{|a_{mn}|}) &= 2ln(x^1)+ln(\sin (x^2))\\
\Rightarrow\quad\quad &\left \{\begin{array}{c}
\Gamma^n_{1n} = \partial_1(ln(\sqrt{a})) = \frac{2}{x^1}\\\\
\Gamma^n_{2n} = \partial_2(ln(\sqrt{a})) = \frac{\cos(x^2)}{\sin(x^2)} =  \cot (x^2)\\\\
\Gamma^n_{3n} = 0\\
\end{array}\right.
\end{align} 
$$\medblackdiamond$$
\newpage

\section{p58-exercise}
\begin{tcolorbox}
Show that for the spherical polar metric 
$$\textbf{2.546}\quad T^n_{\ |n} = \frac{1}{r^2}\partial_r(r^2 \ T^1) + \frac{1}{\sin \theta }\partial_{\theta}(\sin \theta\  T^2) + \partial_{\phi}T^3 $$
Obtain a similar expression for the "Laplacian" $\Delta V$ of an invariant $V$ defined as $$\textbf{2.547}\quad\Delta V = \left( a^{mn}\partial_m V\right)_{|n}$$
\end{tcolorbox}
We have
\begin{align}
\textbf{(2.545)}\quad T^n_{\ |n} &= \frac{1}{\sqrt{a}}\partial_n(\sqrt{a} \ T^n)\\
\text{and from the previous exercise p.58:}\quad \sqrt{a} &= (x^1)^2\sin(x^2)
\end{align}
\begin{align}
\Rightarrow \quad T^n_{\ |n} &= \frac{1}{\sqrt{a}}\left(\sin(x^2) \partial_1[(x^1)^2 T^1]  + (x^1)^2\partial_2 [ \sin (x^2)T^2] + (x^1)^2 \sin (x^2)\partial_3 T^3 \right)\\
&= \frac{1}{x^1} \partial_1[(x^1)^2 T^1]  + \frac{1}{\sin (x^2)}\partial_2 [ \sin (x^2)T^2] + \partial_3 T^3 
\end{align}
Replace in (4) $\quad x^1 =r$, $x^2 =  \theta$ and $x^3 = \phi$
\begin{align}
\ T^n_{\ |n} = \frac{1}{r^2} \partial_r [r^2 \ T^r]  + \frac{1}{\sin \theta}\partial_{\theta} [ \sin \theta \ T^{\theta}] + \partial_{\phi} T^{\phi} 
\end{align}
Let's calculate the Laplacian.
\begin{align}
\Delta V &= \left( a^{mn}\partial_m V\right)_{|n}\\
\text{be}\quad \quad \quad G^n &= a^{mn}\partial_m V\\
\text{then (see exercise p.32) } \quad \quad \left\{ \begin{array}{c}
\ G^1 = \partial_r V\\
\ G^2 = \frac{1}{r^2}\partial_{\theta} V\\
\ G^1 = \frac{1}{r^2 \sin ^2 \theta}\partial_{\phi} V\\
\end{array}\right.
\end{align}
and by the previous result of this exercise
\begin{align}
\Delta V &= G^n_{|n} = \frac{1}{r^2} \partial_r [r^2 \ G^1]  + \frac{1}{\sin \theta}\partial_{\theta} [ \sin \theta \ G^{2}] + \partial_{\phi} G^{3} \\
\ &= \frac{1}{r^2} \partial_r [r^2 \partial_r V]  + \frac{1}{r^2 \sin \theta}\partial_{\theta} [ \sin \theta \ \partial_{\theta} V] + \frac{1}{r^2 \sin ^2 \theta}\partial^2_{\phi} V
\end{align}
$$\medblackdiamond$$
\newpage

\section{p62-exercise}
\begin{tcolorbox}
Prove that if a pair of vectors are unit orthogonal vectors at a point on a curve, and if they are both propagated parallelly along the curve, then they remain unit orthogonal vectors along the curve.
\end{tcolorbox}
Given is, a pair of vectors $U^m$ and $V^m$ which are unit orthogonal vectors at a point on a curve. So,
\begin{align}
\begin{array}{cc}
\text{U is a unit vector (2.302)}& a_{mn}U^m U^n = \epsilon\\
\text{V is a unit vector (2.302)}& a_{mn}V^m V^n = \epsilon\\
\text{U, V are orthogonal (2.317)}& a_{mn}U^m V^n = 0\\
\end{array}
\end{align}
at one point on the curve.\\
We have to prove that the above properties are valid along the curve (i.e. $\forall$ points on the curve) provided that the vectors are propagated // along the curve, which means
\begin{align}
\textbf{(2.512)}\quad\quad \frac{\delta U^r}{\delta u} &= \dv{U^r}{u} + \Gamma^r_{mn}U^m \dv{x^n}{u} = 0
\end{align}
for both vectors $U, V$. Thus,
\begin{align}
\dv{U^r}{u} = - \Gamma^r_{mn}U^m \dv{x^n}{u}
\end{align}\\
i) Consider the magnitude M at a random point on the curve
\begin{align}
\ M &= a_{mn}U^m U^n \\
\Rightarrow \quad\quad \dv{M}{s} &= \dv{a_{mn}}{u}U^m U^n + 2a_{mn}U^m \dv{U^n}{u} 
\end{align}\\
Obviously $M$ and $\dv{M}{s}$ are invariants. Also, we can choose at any point on the curve a Riemaniann coordinate system (RCS) for which the Christoffel symbols vanish at that point. Hence, $\dv{U^r}{u} = 0 $ at that point and the second term in the right part of (5) vanish. (5) becomes then,
\begin{align}
 \dv{M}{s} = \pdv{a^,_{mn}}{x^{,k}}\dv{x^{,k}}{s}U^{,m} U^{,n}  
\end{align}
We also know \textbf{(2.425. page 41)} that $[km,n]^, + [kn,m]^, = \pdv{a^,_{mn}}{x^{,k}}$. But in the chosen coordinate system, $[km,n] = 0$ at the origin of this coordinate system. So by (6) we get $\dv{M}{s} = 0$.\\
So the magnitude is constant along the curve and as we know that a certain point $M =1$:\\
$$\textbf{ U,V are unit vectors along the curve}$$\newpage
ii) Consider now the angle between the vectors $U,V$. Be $A = \cos \ \theta$.By definition 
\begin{align}
\ A &= a_{mn}U ^mV^n\\
\Rightarrow \quad\quad \dv{A}{s} &= \dv{a_{mn}}{u}U^m V^n + a_{mn}(V^m \dv{U^n}{u} +U^m \dv{V^n}{u} )
\end{align}
We follow the same reasoning as in i) and so
$$\dv{A}{s} = 0$$
So, the angle is constant and we know is is $\frac{\pi}{2}$ at a certain point. So,:
$$\textbf{ U,V are orthogonal along the curve}$$

$$\medblackdiamond$$
\newpage

\section{p62-exercise}
\begin{tcolorbox}
Given that $\lambda^r$ is a unit vector field, prove that $$\lambda^r_{\ |s}\lambda_r = 0 \quad \text{and}\quad \lambda^r\lambda_{r|s} = 0 $$
Is the relation $\lambda^r_{\ |s}\lambda_s = 0$ true for a general unit vector field?
\end{tcolorbox}
To simplify the calculation, we choose a random element in the unit vector field and use at that point a Riemaniann coordinate system (RCS). So, we have
\begin{align}
\lambda^r_{\ |s} = \partial_s \lambda^r \quad & \text{and}\quad \lambda_{r|s} = \partial_s \lambda_r\\
\text{as we have a unit vector fields:}\quad\quad a_{mn}\lambda^m\lambda^n &= 1\\
\Leftrightarrow \lambda_n\lambda^n &= 1\quad\quad\text{(by lowering the index m)}\\
\Rightarrow \quad\quad \lambda^n\partial_s \lambda_n + \lambda_n\partial_s \lambda^n &= 0
\end{align}
We prove that $$\lambda^n\partial_s\lambda_n = \lambda_n\partial_s\lambda^n\quad \forall\text{ vector fields}$$
We have the trivial identity
\begin{align}
\partial_s(\lambda^r\lambda_r) &= \partial_s(\lambda^r\lambda_r)\\
\Leftrightarrow \quad\quad \partial_s(a^{rm}\lambda_m\lambda_r) &= \partial_s(a_{rm}\lambda^m\lambda^r)
\end{align}
\begin{lemma}: $\partial_sa^{rm} = 0$ in a Riemaniann coordinate system (i.e. at the origin)\\\\
We have
\begin{align}
\ a^{rm}a_{ms} &= \delta^r_s\\
\Rightarrow a_{ms}\partial_k a^{rm}  & +a^{rm}\partial_k a_{ms} = 0\\
\text{we know (2.618)}\quad\quad \partial_r a_{mn} &= 0\quad\quad\text{at the origin of a RCS}\\
\text{so (8) becomes}\quad\quad a_{ms}\partial_k a^{rm} & = 0\\
\text{multiply (10) by}\quad a^{ns}\quad\Rightarrow \underbrace{a^{ns}a_{ms}}_{= \delta^n_m}\partial_k a^{rm}& = 0\\
\Rightarrow\quad\quad \partial_k a^{rn}& = 0
\end{align}
\end{lemma}
$$\meddiamond$$
Now, expanding (6) and using $\textbf{2.618}$ and the lemma:
\begin{align}
\ a^{rm}\lambda_m\partial_s \lambda_r+ a^{rm} \lambda_r \partial_s \lambda_m &= a_{rm} \lambda^m \partial_s \lambda^r + a_{rm} \lambda^r \partial_s \lambda^m\\
\text{renaming dummy indices:}\quad\quad   a^{rm} \lambda_r \partial_s \lambda_m &= a_{rm} \lambda^r \partial_s \lambda^m \\
\Rightarrow\quad\quad \lambda^m \partial_s \lambda_m &= \lambda_m \partial_s \lambda^m
\end{align}
Considering (5) and (15) we conclude:
\begin{align}
\lambda^n \partial_s \lambda_n &= \lambda_n \partial_s \lambda^n = 0
\end{align}
and as $\partial_s \lambda_n = \lambda_{n|s} $ and $\partial_s \lambda^n = \lambda^n_{\ |s} $ at the origin of the considered coordinate system, we have:
\begin{align}
\lambda^m \lambda_{n|s} &= \lambda_m \lambda^n_{\ |s} = 0
\end{align}\\
$$\meddiamond$$
Is the relation $\lambda^r_{|s}\lambda_s = 0$ true for a general unit vector field?\\
The answer is NO. Let's consider the following unit vector field in a Cartesian Coordinate system:
\begin{figure}[H]
\centering
\begin{minipage}[H]{.4\textwidth}
%\centering
\vspace{0pt}
\includegraphics[scale=.3]{unitvectorfield1.jpg}
\end{minipage}\hfill
\begin{minipage}[H]{0.4\textwidth}
%\centering
\vspace{50pt}
$$V:\mathbb{R}_*^2\rightarrow \mathbb{R}^2|V(x,y) = \left< \frac{x}{\sqrt{x^2+y^2}},-\frac{y}{\sqrt{x^2+y^2}} \right>$$
\end{minipage}
\end{figure}
Put $ r = \sqrt{x^2+y^2}$, we get (as we have a Cartesian Coordinate system, the calculation simplify as the Christoffel symbols vanish and the covariant components of the vectors are equal to their contravariant part):
\begin{align}
\ & \left \{ \begin{array}{c}
\ V^1 = V_1 = +\frac{x}{r}\\
\ V^2 = V_2 = -\frac{y}{r}\\
\end{array}\right.\\
\ & \left \{ \begin{array}{cc}
\ V^1_{\ |1} =  V_{1|1} = \frac{y^2}{r^3}&V^1_{\ |2} =  V_{1|2} = -\frac{xy}{r^3}\\
\ V^2_{\ |1} =  V_{2|1} = \frac{xy}{r^3}&V^2_{\ |2} =  V_{2|2} = -\frac{x^2}{r^3}\\
\end{array}\right.\\
\Rightarrow \quad\quad &\left \{ \begin{array}{c} \  V^1_{\ |s}V_s = V^1_{\ |1}V_1+V^1_{\ |2}V_2 = \frac{y^2}{r^3}\frac{x}{r}+ (-\frac{xy}{r^3})(-\frac{y}{r}) = \frac{xy^2}{r^4} \ne 0\\
\ V^2_{\ |s}V_s = V^2_{\ |1}V_1+V^2_{\ |2}V_2 = \frac{xy}{r^3}\frac{x}{r}+ (-\frac{y}{r})(-\frac{y}{r}) = \frac{x^2 y}{r^4} \ne 0
\end{array} \right.
\end{align}
Just as a check, we calculate $V^r_{|s}V_r$ which should be zero:
\begin{align}
\Rightarrow \quad\quad &\left \{ \begin{array}{c}V^s_{\ |1}V_s = V^1_{\ |1}V_1+V^2_{\ |1}V_2 = (+\frac{y^2}{r^3})\frac{x}{r}+ (+\frac{xy}{r^3})(-\frac{y}{r}) =0\\
\ V^s_{\ |2}V_s = V^1_{\ |2}V_1+V^2_{\ |2}V_2 = (-\frac{xy}{r^3})\frac{x}{r}+ (-\frac{y}{r})(-\frac{x^2}{r^3}) = 0
\end{array} \right.
\end{align}\\\\
Now, let's consider another unit vector field in a Cartesian Coordinate system:
\begin{figure}[H]
\centering
\begin{minipage}[H]{.4\textwidth}
%\centering
\vspace{0pt}
\includegraphics[scale=.3]{unitvectorfield2.jpg}
\end{minipage}\hfill
\begin{minipage}[H]{0.4\textwidth}
%\centering
\vspace{50pt}
$$V:\mathbb{R}_*^2\rightarrow \mathbb{R}^2|V(x,y) = \left< \frac{x}{\sqrt{x^2+y^2}},\frac{y}{\sqrt{x^2+y^2}} \right>$$
\end{minipage}
\end{figure}
\begin{align}
\ & \left \{ \begin{array}{c}
\ V^1 = V_1 = +\frac{x}{r}\\
\ V^2 = V_2 = +\frac{y}{r}\\
\end{array}\right.\\
\ & \left \{ \begin{array}{cc}
\ V^1_{\ |1} =  V_{1|1} = \frac{y^2}{r^3}&V^1_{\ |2} =  V_{1|2} = -\frac{xy}{r^3}\\
\ V^2_{\ |1} =  V_{2|1} = -\frac{xy}{r^3}&V^2_{\ |2} =  V_{2|2} = +\frac{x^2}{r^3}\\
\end{array}\right.\\
\Rightarrow \quad\quad &\left \{ \begin{array}{c} \  V^1_{\ |s}V_s = V^1_{\ |1}V_1+V^1_{\ |2}V_2 = (+\frac{y^2}{r^3})\frac{x}{r}+ (-\frac{xy}{r^3})(+\frac{y}{r}) =  0\\
\ V^2_{\ |s}V_s = V^2_{\ |1}V_1+V^2_{\ |2}V_2 = (-\frac{xy}{r^3})\frac{x}{r}+ (+\frac{y}{r})(+\frac{y}{r}) =  0
\end{array} \right.
\end{align}
Just as a check, we calculate $V^r_{|s}V_r$ which should be zero:
\begin{align}
\Rightarrow \quad\quad &\left \{ \begin{array}{c}V^s_{\ |1}V_s = V^1_{\ |1}V_1+V^2_{\ |1}V_2 = (+\frac{y^2}{r^3})(+\frac{x}{r})+ (-\frac{xy}{r^3})(+\frac{y}{r}) =0\\
\ V^s_{\ |2}V_s = V^1_{\ |2}V_1+V^2_{\ |2}V_2 = (-\frac{xy}{r^3})(+\frac{x}{r})+ (+\frac{y}{r})+\frac{x^2}{r^3}) = 0
\end{array} \right.
\end{align}\\
So, in the second example the relationship $\lambda^r_{|s}\lambda_s = 0$ holds.
Question (to investigate further and later) : does the fact that in the first case $\del \maal \overline{V}  \ne 0$ and in the second case $\del \maal \overline{V}= 0$, means that there is some relation with this expression?
$$\medblackdiamond$$
\newpage

\section{p64-clarification 2.625}
\begin{tcolorbox}
$\textbf{2.625} \quad\quad\quad\quad\quad\quad \dv{ x^r}{x^N} = \frac{X^r}{X^N}$
\end{tcolorbox}
Be $C$ a surface defined by the function $F(x^1,\dots, x^{N-1}) = C$ and  $c_{\perp}$ the curve intersecting the surface $C$ perpendicularly at a point $p$.\\
Along the curve at that point $p$ we have
\begin{align}
\text{as}\quad\quad & \left \{ \begin{array}{cc}
\dv{ x^r}{s}& \text{is the tangent vector along}\quad c_{\perp}\\
\ X^r = a^{rn}\pdv{F}{x^n}& \text{ is orthogonal on the surface (2.623)}\quad C\\
\end{array}\right.\\
\Rightarrow \quad\quad & \dv{ x^r}{s} = kX^r
\end{align}
So, $\dv{ x^r}{s}$ is proportional to $X^r$ (as the curve intersects the surface orthogonally). This means that also all the components (coordinates) of both quantities are proportional. And so,
\begin{align}
\frac{\dv{ x^r}{s}}{\dv{ x^N}{s}} &= \frac{kX^r}{kX^N}\\
\Rightarrow\quad\quad \dv{ x^r}{x^N} &= \frac{X^r}{X^N}
\end{align}
$$\medblackdiamond$$
\newpage

\section{p65-exercise}
\begin{tcolorbox}
Deduce from $\textbf{2.629}$ that $$a^{N \rho} = 0  \quad\quad a^{NN} = \frac{1}{a_{NN}}$$
\end{tcolorbox}
We have (see 2.629):
\begin{align}
\ a_{N\rho} =0\\
\text{and also}\quad\quad a_{Nm}a^{ms} = \delta^s_N
\end{align}
In (2) split the $m$ index in the subspace and the remaining coordinate $N$
\begin{align}
\ a_{N\rho}a^{\rho s} +  a_{NN}a^{N s} &= \delta^s_N\\
\text{as}\quad a_{N\rho} =0 \Rightarrow \quad\quad a_{NN}a^{N s} &= \delta^s_N
\end{align}\\
Case 1: $s\ne N$
\begin{align}
\  a_{NN}a^{N s} =0 \quad \Leftrightarrow \quad a_{NN}a^{N \rho} =0 \quad\quad \text{(as}\quad s\ne N \text{)}\\
\text{as we suppose}\quad a_{NN}\ne 0 \quad \Rightarrow \quad a^{N \rho} =0
\end{align}\\

Case 2: $s= N$
\begin{align}
\  a_{NN}a^{N N} &=1 \\
\Rightarrow \quad a^{N N} &=\frac{1}{a_{NN}}
\end{align}
$$\medblackdiamond$$
\newpage


\section{p69-clarification on 2.645}
\begin{tcolorbox}
In 2.645 we have $$T_{\alpha | \beta} =T_{\alpha || \beta}  +\frac{1}{2}\frac{1}{a_{NN}}\partial_N  a_{\alpha\beta}T_{N}$$ and $$T_{\alpha | \beta} =T_{\alpha || \beta}  +\frac{1}{2}\partial_N  a_{\alpha\beta}T^{N}$$
\end{tcolorbox}
Indeed,
\begin{align}
\ T^N &= a^{mN}T_m\\
\ & = a^{\alpha N}T_{\alpha}+a^{N N}T_{N}\\
\text{but (2.631)}\quad\quad a^{\alpha N} &= 0\\
\Rightarrow \quad\quad T^N &= a^{NN} T_N\\
\text{as}\quad a^{NN}= \frac{1}{a_{NN}} \quad \Rightarrow \quad\quad  T_{\alpha | \beta} &= T_{\alpha || \beta}  + \frac{1}{2}\partial_N  a_{\alpha\beta}T^{N}
\end{align}
$$\medblackdiamond$$
\newpage
\section{p69-exercise}
\begin{tcolorbox}
Show that
$$\textbf{2.648}\quad\quad T^{\alpha}_{\ |\beta} = T^{\alpha}_{\ ||\beta} + \half a^{\alpha \mu} \partial_N a_{\mu\beta}T^N$$
$$\textbf{2.649}\quad\quad T^{N}_{\ |\alpha} = \partial_{\alpha}T^{N} - \frac{1}{2 a_{NN}} \partial_N a_{\alpha\mu}T^{\mu} + \frac{1}{2 a_{NN}} \partial_{\alpha} a_{NN}T^{N}$$
$$\textbf{2.650}\quad\quad T^{\alpha}_{\ |N} = \partial_{N}T^{\alpha}  + \half a^{\alpha\mu} \partial_N a_{\mu\sigma}T^{\sigma} - \half a^{\alpha\mu}  \partial_{\mu} a_{NN}T^{N}$$
\end{tcolorbox}
i) $T^{\alpha}_{\ |\beta} = T^{\alpha}_{\ ||\beta} + \half a^{\alpha \mu} \partial_N a_{\mu\beta}T^N$\\
\begin{align}
\textbf{(2.520)}\quad\quad \Rightarrow \quad\quad T^{\alpha}_{\ |\beta} &= \partial_{\beta}T^{\alpha}+\Gamma^{\alpha}_{m\beta}T^m \quad\quad\text{(}m = 1,\dots,N \text{)}\\
\Leftrightarrow \quad\quad T^{\alpha}_{\ |\beta} &= \underbrace{ \partial_{\beta}T^{\alpha}+ \Gamma^{\alpha}_{\mu \beta} T^{\mu}}_{T^{\alpha}_{ \ || \beta}} +\Gamma^{\alpha}_{N \beta}T^{N}\\
\textbf{(2.639)}\quad\quad \Gamma^{\alpha}_{N\beta} &= \half a^{\alpha \mu}\partial_N a^{\mu \beta}\\
\text{(2) and (3): }\quad\quad T^{\alpha}_{\ |\beta} &= T^{\alpha}_{\ ||\beta} + \half a^{\alpha \mu} \partial_N a_{\mu\beta}T^N
\end{align}
$$\meddiamond$$
Remark: We also use $\textbf{(2.639)}$ for the two other identities.\\\\
ii) $T^{N}_{\ |\alpha} = \partial_{\alpha}T^{N} - \frac{1}{2 a_{NN}} \partial_N a_{\alpha\mu}T^{\mu} + \frac{1}{2 a_{NN}} \partial_{\alpha} a_{NN}T^{N}$\\
\begin{align}
\textbf{(2.520)}\quad\quad \Rightarrow \quad\quad T^{N}_{\ |\alpha} &= \partial_{\alpha}T^{N}+\Gamma^{N}_{m\alpha}T^m \quad\quad\text{(}m = 1,\dots,N \text{)}\\
\Leftrightarrow \quad\quad T^{N}_{\ |\alpha} &=  \partial_{\beta}T^{\alpha}+ \underbrace{\Gamma^{N}_{\sigma \alpha}}_{ - \frac{1}{2a_{NN}}\partial_N a_{\sigma\alpha}} T^{\sigma } +\underbrace{\Gamma^{N}_{N \alpha}}_{ \frac{1}{2a_{NN}}\partial_{\alpha} a_{NN}}T^{N}\\
\Rightarrow \quad\quad T^{N}_{\ |\alpha} &=  \partial_{\beta}T^{\alpha} - \frac{1}{2a_{NN}}\partial_N a_{\sigma\alpha}T^{\sigma } +\frac{1}{2a_{NN}}\partial_{\alpha} a_{NN}T^{N}
\end{align}\\
iii) $T^{\alpha}_{\ |N} = \partial_{N}T^{\alpha}  + \half a^{\alpha\mu} \partial_N a_{\mu\sigma}T^{\sigma} - \half a^{\alpha\mu}  \partial_{\mu} a_{NN}T^{N}$\\
\begin{align}
\textbf{(2.520)}\quad\quad \Rightarrow \quad\quad T^{\alpha}_{\ |N} &= \partial_{N}T^{\alpha}+\Gamma^{\alpha}_{mN}T^m \quad\quad\text{(}m = 1,\dots,N \text{)}\\
\Leftrightarrow \quad\quad T^{\alpha}_{\ |N} &=  \partial_{N}T^{\alpha}+ \underbrace{\Gamma^{\alpha}_{\sigma N }}_{ \half a^{\alpha \mu}\partial_N a_{\mu\sigma}}  T^{\sigma }+\underbrace{\Gamma^{\alpha}_{N N}}_{ -\half a^{\alpha\mu}\partial_{\mu} a_{NN}}T^{N}\\
\Rightarrow \quad\quad T^{\alpha}_{\ |N} &=  \partial_{N}T^{\alpha}+ \half a^{\alpha \mu}\partial_N a_{\mu\sigma}T^{\sigma } -\half a^{\alpha\mu}\partial_{\mu} a_{NN}T^{N}
\end{align}
$$\medblackdiamond$$
\newpage

\section{p71-exercise}
\begin{tcolorbox}
Write down equation 2.643 tot 2.650 for the special cae of a geodesic normal coordinate system.
\end{tcolorbox}
\begin{align}
\ \textbf{(2.643)}\quad \quad T_{\alpha || \beta} &= \partial_{\beta}T_{\alpha} - \Gamma^{\gamma}_{\alpha\beta}T_{\gamma}\quad\quad \text{(does not change)}\\
\textbf{(2.644)}\quad \quad T_{\alpha | \beta} &=T_{\alpha || \beta}  - \underbrace{\Gamma^{N}_{\alpha\beta}}_{=\frac{1}{2} \frac{1}{a_{NN}}\partial_N  a_{\alpha\beta}}T_{N}\\
&=T_{\alpha || \beta}  +\frac{1}{2} \epsilon\partial_N  a_{\alpha\beta}T_{N}\\
\textbf{(2.645)}\quad \quad T_{\alpha | \beta} &=T_{\alpha || \beta}  +\frac{1}{2}\partial_N  a_{\alpha\beta}T^{N}\quad\quad \text{(does not change)}\\
\textbf{(2.646)}\quad \quad T_{N| \alpha } &=\partial_{\alpha}T_N  -\frac{1}{2}\partial_N  a_{\mu\alpha}T^{\mu} -\frac{1}{2}\underbrace{\partial_{\alpha}  a_{NN}}_{=0}T^{N}\\
&=\partial_{\alpha}T_N  -\frac{1}{2}\partial_N  a_{\mu\alpha}T^{\mu} \\
\textbf{(2.647)}\quad \quad T_{ \alpha |N } &=\partial_N T_{\alpha}  -\frac{1}{2}\partial_N  a_{\mu\alpha}T^{\mu} -\frac{1}{2}\underbrace{\partial_{\alpha}  a_{NN}}_{=0}T^{N}\\
&=\partial_N T_{\alpha}  -\frac{1}{2}\partial_N  a_{\mu\alpha}T^{\mu} \\
\textbf{(2.648)}\quad \quad T^{\alpha}_{ \  | \beta} &=T^{\alpha}_{ || \beta}  + \frac{1}{2}a^{\alpha\mu}\partial_N  a_{\mu\beta}T_{N}\quad\quad\text{(does not change)}\\
\textbf{(2.649)}\quad \quad T^N_{ \ | \alpha} &=\partial_{\alpha}T^N  -\frac{1}{2}\frac{1}{a_{NN}}\partial_N  a_{\mu\alpha}T^{\mu} -\frac{1}{2}\frac{1}{a_{NN}}\underbrace{\partial_{\alpha}  a_{NN}}_{=0}T^{N}\\
\ &= \partial_{\alpha}T^N  -\frac{1}{2}\epsilon\partial_N  a_{\mu\alpha}T^{\mu} \\
\textbf{(2.650)}\quad \quad T^{\alpha}_{\ |N} &=\partial_N T^{\alpha}  +\frac{1}{2}a^ {\alpha\mu}\partial_N  a_{\mu\sigma}T^{\sigma} -\frac{1}{2}a^{\alpha\mu}\underbrace{\partial_{\mu}  a_{NN}}_{=0}T^{N}\\
\ &=\partial_N T^{\alpha}  +\frac{1}{2}a^ {\alpha\mu}\partial_N  a_{\mu\sigma}T^{\sigma} 
\end{align}
\\\\
To investigate: note (3) and (4) which suggest that $\epsilon T_{N} = T^{N}$. Prove formally?
$$\medblackdiamond$$
\newpage


\section{p73-Clarification 2.706}
\begin{tcolorbox}
... Let us now define a unit vector $\lambda^r_{(2)}$ and a positive invariant $\kappa_{(2)}$ by the equation \\
\begin{align}
\left \{ \begin{array}{c}
\frac{\delta\lambda_{(1)}^r}{\delta s} = \kappa_{(2)}\lambda^r_{(2)} - \epsilon\epsilon_{(1)}\kappa_{(1)}\lambda^r\\
\epsilon_{(2)}\lambda^n_{(2)}\lambda_{(2)n} = 1
\end{array} \right.
\end{align}  
\end{tcolorbox}
We can state that $\kappa_{(2)}$ is an invariant but one has to check whether the expression $(1)$ implies that $\kappa_{(2)}$ is indeed invariant.\\
What we know is that $\lambda^r, \frac{\delta \lambda^r}{\delta s},\frac{\delta\lambda_{(1)}^r}{\delta s},  \lambda^r_{(2)}$ are contravariant vectors. Also $\kappa_{(1)}$ is an invariant as $\frac{\delta\lambda^r}{\delta s} = \kappa_{(1)}\lambda^r_{(1)}$ and the magnitude of $\frac{\delta\lambda^r}{\delta s}$ does not depend on the coordinate system. So,
\begin{align}
\text{(1)}\times \lambda_{(2)r} \quad\Rightarrow \quad\quad \frac{\delta\lambda_{(1)}^r}{\delta s}\lambda_{(2)r} &= \kappa_{(2)}\lambda^r_{(2)}\lambda_{(2)r} - \epsilon\epsilon_{(1)}\kappa_{(1)}\lambda^r\lambda_{(2)r}\\
\Rightarrow \quad\quad \kappa_{(2)}\underbrace{\lambda^r_{(2)}\lambda_{(2)r}}_{\text{invariant}} &= \underbrace{\frac{\delta\lambda_{(1)}^r}{\delta s}\lambda_{(2)r}}_{\text{invariant}}  + \underbrace{\epsilon\epsilon_{(1)}}_{\text{invariant}} \underbrace{\kappa_{(1)}}_{\text{invariant}} \underbrace{\lambda^r \lambda_{(2)r}}_{\text{invariant}} \\
\Rightarrow \quad\quad \kappa_{(2)}&= \text{invariant} 
\end{align}
$$\medblackdiamond$$
\newpage

\section{p74-Clarification 2.710}
\begin{tcolorbox}
\begin{align}
\textbf{2.710}\quad\quad\left \{ \begin{array}{c}
\frac{\delta\lambda_{(M-1)}^r}{\delta s} = \kappa_{(M)}\lambda^r_{(M)} - \epsilon_{(M-2)}\epsilon_{(M-1)}\kappa_{(M-1)}\lambda^r_{(M-2)}\\
\epsilon_{(M-1)}\lambda^n_{(M-1)}\lambda_{(M-1)n} = 1\quad\quad \text{(M=1,2,...,N)}
\end{array} \right.
\end{align}
... It is easily proved by mathematical induction that the whole sequence of vectors defined by 2.710 are perpendicular to the tangent and to one another ...
\end{tcolorbox}
We already know from 2.703 to 2.709 that $\lambda^r, \lambda_{(1)}^r,\lambda_{(2)}^r,\lambda_{(3)}^r$, satisfying equations (1), are all mutually perpendicular. Let us assume that the orthogonality for the set $\{\lambda_{(k)}^r:k= 0,1,2,3,..., M-1\}$ has been verified. We prove by induction that then, $\lambda_{(M)}^r$ will be orthogonal to all elements of the set.\\
i) Consider the set $\{\lambda_{(k)}^r:k= 0,1,2,3,..., M-3\}$ where we already know that $\lambda_{(k)}^r$ are mutually perpendicular and also $\lambda_{(k)}^r \perp \lambda_{(M-1)}^r $, $\lambda_{(k)}^r \perp \lambda_{(M-2)}^r$ and $\lambda_{(M-1)}^r \perp \lambda_{(M-1)}^r \quad \forall k$.
\begin{align}
\text{(1)}\times \lambda_{(k)r}\quad\Rightarrow\quad\quad \frac{\delta\lambda_{(M-1)}^r}{\delta s}\lambda_{(k)r} &= \kappa_{(M)}\lambda^r_{(M)}\lambda_{(k)r} - \epsilon_{(M-2)}\epsilon_{(M-1)}\kappa_{(M-1)}\underbrace{\lambda^r_{(M-2)}\lambda_{(k)r}}_{=0}\\
\text{We have}  \quad \quad\quad\quad\quad\lambda_{(k)r}\lambda^r_{(M-1)} &=0\\
\Rightarrow \quad \quad\quad\quad\quad\ \frac{\delta\lambda_{(k)r}\lambda_{(M-1)}^r}{\delta s} &= \lambda_{(M-1)}^r\frac{\delta\lambda_{(k)r}}{\delta s}+\lambda_{(k)r}\delta\frac{\lambda_{(M-1)}^r}{\delta s}=0\\
\Rightarrow \quad \quad\quad\quad\quad\ \lambda_{(k)r}\delta\frac{\lambda_{(M-1)}^r}{\delta s} &= - \lambda_{(M-1)}^r\frac{\delta\lambda_{(k)r}}{\delta s}\\
\text{We have}\quad \quad\quad\quad\quad\frac{\delta\lambda_{(k)r}}{\delta s} &= \kappa_{(k+1)}\lambda_{(k+1)r} - \epsilon_{(k)}\epsilon_{(k-1)}\kappa_{(k)}\lambda_{(k-1)r}\\
\text{(5) and (6)}\Rightarrow \quad \quad\quad\quad\quad\ \lambda_{(k)r}\delta\frac{\lambda_{(M-1)}^r}{\delta s} &= -\kappa_{(k+1)}\underbrace{\lambda_{(k+1)r} \lambda_{(M-1)}^r}_{=0} - \epsilon_{(k)}\epsilon_{(k-1)}\kappa_{(k)}\underbrace{\lambda_{(k-1)r}\lambda_{(M-1)}^r}_{=0}\\
\text{From (2)}\Rightarrow \quad \quad\quad\quad\quad\ \kappa_{(M)}\lambda^r_{(M)}\lambda_{(k)r}&=0\\
\Rightarrow \quad \quad\quad\quad\quad\ \lambda^r_{(M)}& \perp\lambda_{(k)r}\quad\quad \forall k= 0,1,2,3,..., M-3 
\end{align}\\\\
ii) Consider the case $k = M-1$\\\begin{align}
\text{(1)}\times \lambda_{(M-1)r}\quad \frac{\delta\lambda_{(M-1)}^r}{\delta s}\lambda_{(M-1)r} &= \kappa_{(M)}\lambda^r_{(M)}\lambda_{(M-1)r} - \epsilon_{(M-2)}\epsilon_{(M-1)}\kappa_{(M-1)}\underbrace{\lambda^r_{(M-2)}\lambda_{(M-1)r}}_{=0}\\
\text{from (2.530):}\quad\quad \frac{\delta\lambda_{(M-1)}^r}{\delta s}\lambda_{(M-1)r}  &= \half\underbrace{\frac{\delta\lambda_{(M-1)r}\lambda_{(M-1)}^r}{\delta s}}_{=0\text{ as }\lambda_{(M-1)r}\lambda_{(M-1)}^r =  \epsilon_{(M-1)}}\\
\Rightarrow \quad \quad\quad\quad\quad \kappa_{(M)}\lambda^r_{(M)}\lambda_{(M-1)r}&=0\\
\Rightarrow \quad \quad\quad\quad\quad \lambda_{(M-1)r} & \perp\lambda_{(M)r}
\end{align}

iii) Consider the case $k = M-2$\\\begin{align}
\text{(1)}\times \lambda_{(M-2)r}\quad \frac{\delta\lambda_{(M-1)}^r}{\delta s}\lambda_{(M-2)r} &= \kappa_{(M)}\lambda^r_{(M)}\lambda_{(M-2)r} - \epsilon_{(M-2)}\epsilon_{(M-1)}\kappa_{(M-1)}\underbrace{\lambda^r_{(M-2)}\lambda_{(M-2)r}}_{=\epsilon_{(M-2)}}\\
\Rightarrow \quad \quad\quad\quad\quad\frac{\delta\lambda_{(M-1)}^r}{\delta s}\lambda_{(M-2)r} &= \kappa_{(M)}\lambda^r_{(M)}\lambda_{(M-2)r} - \epsilon_{(M-1)}\kappa_{(M-1)}\underbrace{\epsilon_{(M-2)}\epsilon_{(M-2)}}_{=1}\\
\Rightarrow \quad \quad\quad\quad\quad\frac{\delta\lambda_{(M-1)}^r}{\delta s}\lambda_{(M-2)r} &= \kappa_{(M)}\lambda^r_{(M)}\lambda_{(M-2)r} - \epsilon_{(M-1)}\kappa_{(M-1)}\\
\text{We have}  \quad \quad\quad\quad\quad\lambda_{(M-1)}^r\lambda_{(M-2)r} &=0\\
\Rightarrow \quad \quad\quad\quad\quad\ \lambda_{(M-2)r}\frac{\delta\lambda_{(M-1)}^r}{\delta s} &= -\lambda_{(M-1)}^r\frac{\delta\lambda_{(M-2)r}}{\delta s}\\
\text{We have also }  \quad\frac{\delta\lambda_{(M-2)r}}{\delta s} &= \kappa_{(M-1)}\lambda_{(M-1)r} - \epsilon_{(M-3)}\epsilon_{(M-2)}\kappa_{(M-2)}\lambda_{(M-3)r}\\
\text{(19)}\times \lambda^r_{(M-1)} \text{ and (18): }  \lambda_{(M-2)r}\frac{\delta\lambda_{(M-1)}^r}{\delta s} &= -\kappa_{(M-1)}\underbrace{\lambda^r_{(M-1)}\lambda_{(M-1)r}}_{=\epsilon_{(M-1)}} - \epsilon_{(M-3)}\epsilon_{(M-2)}\kappa_{(M-2)}\underbrace{\lambda^r_{(M-3)}\lambda_{(M-1)r}}_{=0}\\
\Rightarrow \quad \quad\quad\quad\quad\ \lambda_{(M-2)r}\frac{\delta\lambda_{(M-1)}^r}{\delta s} &= -\kappa_{(M-1)}\epsilon_{(M-1)}\\
\text{(16) and (21):}\quad \quad\quad\quad\quad -\kappa_{(M-1)}\epsilon_{(M-1)} &= \kappa_{(M)}\lambda^r_{(M)}\lambda_{(M-2)r} - \epsilon_{(M-1)}\kappa_{(M-1)}\\
\Rightarrow \quad \quad\quad\quad\quad \kappa_{(M)}\lambda^r_{(M)}\lambda_{(M-2)r}&=0\\
\Rightarrow \quad \quad\quad\quad\quad \lambda_{(M-2)r}\perp\lambda_{(M)r}
\end{align}
With, i), ii), iii) all possible cases are covered which makes the proof complete.
$$\medblackdiamond$$
\newpage

\section{p75-Clarification 2.714}
\begin{tcolorbox}
$\textbf{2.714} \quad \quad (\kappa_{(1)})^2 = \epsilon_{(1)} a_{mn} \frac{\delta \lambda^{m}}{\delta s} \frac{\delta \lambda^{n}}{\delta s}$,   $\quad \quad \epsilon_{(1)} = \pm 1$
\end{tcolorbox}
\begin{align}
\ \frac{\delta \lambda^{n}}{\delta s} &= \kappa_{(1)}\lambda_{(1)}^{n}\\
\text{(1)}\times \text{(1)}\quad\Rightarrow \quad\quad \frac{\delta \lambda^{m}}{\delta s}\frac{\delta \lambda^{n}}{\delta s} &= (\kappa_{(1)})^2 \lambda_{(1)}^{m}\lambda_{(1)}^{n}\\
\text{(2)}\times a_{mn} \Rightarrow\quad\quad a_{mn}\frac{\delta \lambda^{m}}{\delta s}\frac{\delta \lambda^{n}}{\delta s} &= a_{mn}(\kappa_{(1)})^2 \lambda_{(1)}^{m}\lambda_{(1)}^{n}\\
\ &= (\kappa_{(1)})^2 \underbrace{\lambda_{(1)m} \lambda_{(1)}^{n}}_{=\epsilon_{(1)}}\\
\ &= (\kappa_{(1)})^2 
\end{align}
$$\medblackdiamond$$
\newpage


\section{p75-exercise}
\begin{tcolorbox}
For positive definite metric forms, write out explicitly the Frenet formulae for the case N=2, 3 and 4.
\end{tcolorbox}
The general Frenet formulae are 
\begin{align}
\left \{ \begin{array}{c}
\frac{\delta\lambda_{(M-1)}^r}{\delta s} = \kappa_{(M)}\lambda^r_{(M)} - \epsilon_{(M-2)}\epsilon_{(M-1)}\kappa_{(M-1)}\lambda^r_{(M-2)}\\
\epsilon_{(M-1)}\lambda^n_{(M-1)}\lambda_{(M-1)n} = 1\quad\quad \text{(M=1,2,...,N)}
\end{array} \right.
\end{align}
As $\Phi$ is positive definite, we have $\epsilon_{(k)} = 1\quad \forall k$
\begin{center}
\begin{tabular}{ |c|c|c|c| } 
\hline
N=2 & N=3 & N=4 \\
\hline
& &\\
$\frac{\delta\lambda^r}{\delta s} = \kappa_{(1)}\lambda^r_{(1)} $ & $\frac{\delta\lambda^r}{\delta s} = \kappa_{(1)}\lambda^r_{(1)} $& $\frac{\delta\lambda^r}{\delta s} = \kappa_{(1)}\lambda^r_{(1)} $ \\ 
$\frac{\delta\lambda_{(1)}^r}{\delta s} = \kappa_{(2)}\lambda^r_{(2)} - \kappa_{(1)}\lambda^r$& $\frac{\delta\lambda_{(1)}^r}{\delta s} = \kappa_{(2)}\lambda^r_{(2)} - \kappa_{(1)}\lambda^r$ & $\frac{\delta\lambda_{(1)}^r}{\delta s} = \kappa_{(2)}\lambda^r_{(2)} - \kappa_{(1)}\lambda^r$ \\ 
& $\frac{\delta\lambda_{(2)}^r}{\delta s} = \kappa_{(3)}\lambda^r_{(3)} - \kappa_{(2)}\lambda^r_{(1)}$ & $\frac{\delta\lambda_{(2)}^r}{\delta s} = \kappa_{(3)}\lambda^r_{(3)} - \kappa_{(2)}\lambda^r_{(1)}$ \\
& & $\frac{\delta\lambda_{(3)}^r}{\delta s} = \kappa_{(4)}\lambda^r_{(4)} - \kappa_{(3)}\lambda^r_{(2)}$ \\
$\lambda^n\lambda_n= 1$&$\lambda^n\lambda_n= 1$&$\lambda^n\lambda_n= 1$\\
$\lambda_{(1)}^n\lambda_{(1)n}= 1$&$\lambda_{(1)}^n\lambda_{(1)n}= 1$&$\lambda_{(1)}^n\lambda_{(1)n}= 1$\\
&$\lambda_{(2)}^n\lambda_{(2)n}= 1$&$\lambda_{(2)}^n\lambda_{(2)n}= 1$\\
&&$\lambda_{(3)}^n\lambda_{(3)n}= 1$\\
\hline
\end{tabular}
\end{center}
Taking into account that $\kappa_{(N)} = 0$ for a space $V_N$, we get,
\begin{center}
\begin{tabular}{ |c|c|c|c| } 
\hline
N=2 & N=3 & N=4 \\
\hline
& &\\
$\frac{\delta\lambda^r}{\delta s} = \kappa_{(1)}\lambda^r_{(1)} $ & $\frac{\delta\lambda^r}{\delta s} = \kappa_{(1)}\lambda^r_{(1)} $& $\frac{\delta\lambda^r}{\delta s} = \kappa_{(1)}\lambda^r_{(1)} $ \\ 
& &\\
$\frac{\delta\lambda_{(1)}^r}{\delta s} =  - \kappa_{(1)}\lambda^r$& $\frac{\delta\lambda_{(1)}^r}{\delta s} = \kappa_{(2)}\lambda^r_{(2)} - \kappa_{(1)}\lambda^r$ & $\frac{\delta\lambda_{(1)}^r}{\delta s} = \kappa_{(2)}\lambda^r_{(2)} - \kappa_{(1)}\lambda^r$ \\ 
& &\\
& $\frac{\delta\lambda_{(2)}^r}{\delta s} =  - \kappa_{(2)}\lambda^r_{(1)}$ & $\frac{\delta\lambda_{(2)}^r}{\delta s} = \kappa_{(3)}\lambda^r_{(3)} - \kappa_{(2)}\lambda^r_{(1)}$ \\
& &\\
& & $\frac{\delta\lambda_{(3)}^r}{\delta s} =  - \kappa_{(3)}\lambda^r_{(2)}$ \\
& &\\
$\lambda^n\lambda_n= 1$&$\lambda^n\lambda_n= 1$&$\lambda^n\lambda_n= 1$\\
& &\\
$\lambda_{(1)}^n\lambda_{(1)n}= 1$&$\lambda_{(1)}^n\lambda_{(1)n}= 1$&$\lambda_{(1)}^n\lambda_{(1)n}= 1$\\
& &\\
&$\lambda_{(2)}^n\lambda_{(2)n}= 1$&$\lambda_{(2)}^n\lambda_{(2)n}= 1$\\
& &\\
&&$\lambda_{(3)}^n\lambda_{(3)n}= 1$\\
& &\\
\hline
\end{tabular}
\end{center}
$$\medblackdiamond$$
\newpage

\section{p76-exercise}
\begin{tcolorbox}
In an Euclidean space $V_N$, the fundamental form is given as $\Phi = dx^n dx^n$. Show that a curve which has $\kappa_{(2)} = 0$ and $\kappa_{(1)} = \text{constant}$ satisfies equations of the form
$$x^r = A^r\cos\kappa_{(1)}s + B^r\sin\kappa_{(1)}s + C^r$$ where $A^r, B^r, C^r$ are constants satisfying $$ A^rA^R = B^rB^r = \frac{1}{\kappa_{(1)}^2},\quad A^rB^r = 0$$
so that $A^r$ and $B^r$ are vectors of equal magnitude and perpendicular to one another. (This curve is a circle in the N-space)
\end{tcolorbox}
\begin{align}
\text{What we know}\quad\quad\quad\quad \Phi &= dx^n dx^n\\
\Rightarrow \quad\quad\quad\quad \left(a_{mn}\right) &= \left(\delta^m_n\right)\\
\text{and given } \spatie \kappa_{(1)} = \text{constant}& \quad \kappa_{(2)} = 0\quad \epsilon_{(1)}=\epsilon_{(2)}, \dots = 1\\
\text{we have (2.705) }\quad\quad\quad\quad \frac{\delta\lambda^r}{\delta s}&=  \kappa_{(1)} \frac{\delta\lambda_{(1)}^r}{\delta s} \quad \quad \text{with }\quad \lambda^r = \dv{x^r}{s}\\
\text{but}\quad\left(a_{mn}\right) = \left(\delta^m_n\right)\quad\Rightarrow\spatie \frac{\delta\lambda^r}{\delta s} &= \dv{\lambda^r}{s}\\
\text{(4) and (5)}\quad\Rightarrow\spatie \dv{\lambda^r}{s} &= \kappa_{(1)} \frac{\delta\lambda_{(1)}^r}{\delta s}\\
\text{also}\spatie \frac{\delta\lambda_{(1)}^r}{\delta s} &= \underbrace{\kappa_{(1)}}_{=0} \frac{\delta\lambda_{(1)}^r}{\delta s}-  \kappa_{(1)} \frac{\delta\lambda_{(1)}^r}{\delta s}
\end{align}
Hence we get the following set of equations
\begin{align}
\left \{ \begin{array}{c}
\dv{x^r}{s} = \lambda^r \\\\
\dv{\lambda^r}{s} = \kappa_{(1)} \lambda_{(1)}^r\\\\
\dv{\lambda_{(1)}^r}{ s} = -  \kappa_{(1)} \lambda_{(1)}^r\\\\
\kappa_{(1)} = \kappa\quad \text{(=constant)}\\\\
\kappa_{(2)} = 0\\\\
\lambda^n\lambda_n = 1\\\\
\lambda_{(1)}^n\lambda_{(1)n} = 1\\
\end{array} \right.\\
\text{(8)}\quad \Rightarrow \spatie \dv[2]{\lambda_{(1)}^r}{s} + \kappa ^2 \lambda_{(1)}^r = 0
\end{align}
Solving the ODE (9). Put $ e^{rs} = \lambda_{(1)}^k$
\begin{align}
\text{(9):}\spatie&  r^2 + \kappa^2 = 0\\
\Rightarrow \spatie & r = \pm \imath \kappa\\
\text{Hence, a general solution of (9) is of the form:} \spatie & \lambda_{(1)}^r = p^r e^{ \imath \kappa s}  + q^r e^{ -\imath \kappa s}\\
\text{put}\quad  p^r+q^r = A^{,r}\quad &\text{and}\quad p^r-q^r = B^{,r}\\
\Leftrightarrow \spatie p^r = \frac{A^{,r}+B^{,r}}{2} &\text{and}\quad p^r=\frac{A^{,r}-B^{,r}}{2}\\
\text{(12) can then be written as }\quad  \lambda_{(1)}^r = A^{,r}\frac{ e^{ \imath \kappa s}+  e^{ -\imath \kappa s}}{2} & + B^{,r}\frac{ e^{ \imath \kappa s}- e^{ -\imath \kappa s}}{2}\\
\text{or}\quad  \lambda_{(1)}^r = A^{,r}\cos \kappa s & + B^{,r}\sin \kappa s\\
\text{We have (8)}\spatie \spatie  \lambda^r =  & -  \kappa_{(1)} \dv{\lambda_{(1)}^r}{ s} \\
\dv{(16)}{s}\quad\text{and (17)}\Rightarrow\spatie \lambda^r =  A^{,r}\sin \kappa s & - B^{,r}\cos \kappa s\\
\text{as}\quad \lambda^r = \dv{x^r}{s}\quad\text{ with (18)}\quad \Rightarrow \spatie x^r = - \frac{A^{,r}}{\kappa}\cos \kappa s &  - \frac{B^{,r}}{\kappa}\sin \kappa s + C^r\\
\end{align}
Replace $- \frac{A^{,r}}{\kappa}$ with $A^{r}$ and $- \frac{B^{,r}}{\kappa}$ with $B^{r}$, we get then the following set of equations,

\begin{align}
\left \{ \begin{array}{c}
x^r = A^{r}\cos \kappa s   + B^{,r}\sin \kappa s + C^r\\
\lambda^r =  -\kappa A^{r}\sin \kappa s  +\kappa B^{r}\cos \kappa s\\
\lambda_{(1)}^r = - \kappa A^{r}\cos \kappa s  - \kappa B^{r}\sin \kappa s\\
\end{array} \right.\\
\text{with the following constraints}\spatie \lambda^n\lambda_n = 1\spatie 
\lambda_{(1)}^n\lambda_{(1)n} &= 1\\
\lambda^n\lambda_n = 1\quad\Rightarrow \kappa^2 A^r A^r \sin ^2 \kappa s+ \kappa^2 B^r B^r \cos ^2 \kappa s - 2 \kappa^2 A^rB^r\sin\kappa s\cos \kappa s &= 1\\
\text{or} \spatie A^r A^r \sin ^2 \kappa s+  B^r B^r \cos ^2 \kappa s - 2 A^rB^r\sin\kappa s\cos \kappa s &= \frac{1}{\kappa^2 }\\
\lambda_{(1)}^n\lambda_{(1)n} = 1\quad\Rightarrow \kappa^2 A^r A^r \cos ^2 \kappa s+ \kappa^2 B^r B^r \sin ^2 \kappa s + 2 \kappa^2 A^rB^r\sin\kappa s\cos \kappa s &= 1\\
\text{or} \spatie A^r A^r \cos ^2 \kappa s+  B^r B^r \sin ^2 \kappa s + 2 A^rB^r\sin\kappa s\cos \kappa s &= \frac{1}{\kappa^2 }\\
\text{Choose }\quad \kappa s = \frac{\pi}{2}\quad\text{and} \quad \kappa s = 0\\
\Rightarrow \spatie A^r A^r =  \frac{1}{\kappa^2 }\quad\text{and}\quad B^r B^r =  \frac{1}{\kappa^2 }\\
\text{Morover considering (26)-(24) and (28)}\quad \Rightarrow \spatie 2A^rB^r\sin \kappa s \cos \kappa s =0 \quad \forall \kappa s\\
\Rightarrow \spatie A^rB^r=0
\end{align}
Note: when deriving expressions $(23)$ and $(26)$ we use the fact that $\left(a_{mn}\right) =  \left(a^{mn}\right) = \left(\delta^m_n\right) $
$$\medblackdiamond$$
\newpage

\section{p78-exercise 1}
\begin{tcolorbox}
For cylindrical coordinates in Euclidean 3-space, write down the metric form by inspection of a diagram showing a general infinitesimal displacement, and calculate all the Christoffel symbols of both kinds.
\end{tcolorbox}
\begin{figure}[h]
\centering
\begin{minipage}[t]{.5\textwidth}
%\centering
\vspace{0pt}
\includegraphics[scale=.4]{polar3d.jpg}
\end{minipage}\hfill
\end{figure}
From the figure we get (assuming an infinitesimal displacement, we may approximate $\left| \overrightarrow{SS^{,}} \right|$ with the arclength $r d\theta$ and assume $\left|  \overrightarrow{SÂ°S^{,,}} \right| \perp \left|  \overrightarrow{GS^{,}} \right|$) Hence, the infinitesimal displacement from S
\begin{align}
\ ds^2 &= \left| \overrightarrow{SS^{,}} \right|^2 + \left| \overrightarrow{S^{,,}P^{,}} \right|^2+\left| \overrightarrow{P^{,}J} \right|^2\\
\ &= dr^2 + ((r+dr)d\theta)^2 + dz^2\\
\ &= dr^2 + r^2d\theta^2 + dz^2\\
\text{Hence} \spatie &\left(a_{mn}\right) = \begin{pmatrix}
 1& 0 & 0 \\
 0&  r^2&0  \\
 0&0  &1  \\
\end{pmatrix}\quad\text{and}\quad \left(a_{mn}\right) = \begin{pmatrix}
 1& 0 & 0 \\
 0&  ^\frac{1}{r^2}&0  \\
 0&0  &1  \\
\end{pmatrix}
\end{align}
Note that all $a_{mn} = 0 \quad \forall m\ne n$. So,
\begin{align}
\left \{ \begin{array}{c}
\ [r \ r,r]=[\theta \  \theta, \theta] = [z \ z,z] = 0\\
\ [r \ \theta,r]=[r \ r, \theta] = [r \ r,z] = 0\\
\ [r \ z,\theta]=[z \  \theta, r] = [z \ \theta,z] = 0\\
\end{array}\right.\\
\text{But:}\spatie [\theta \ \theta,r]= -r \quad\text{and}\quad [r \  \theta, \theta] = r\\
\text{Hence}\spatie \left \{ \begin{array}{c}
\Gamma^m_{nk} = 0 \quad\forall\quad (nk) \ne (r, \theta), (\theta, \theta)\\\\
\Gamma^{\theta}_{r\theta} = \frac{1}{r} \quad\text{and}\quad \Gamma^r_{\theta\theta} = -r
\end{array}\right.\
\end{align}

$$\medblackdiamond$$
\newpage

\section{p78-exercise 2}
\begin{tcolorbox}
If $a_{rs}$ and $b_{rs}$ are covariant tensors, show that the roots of the determinant equation $$\left|Xa_{rs} - b_{rs}\right |= 0$$ are invariants.
\end{tcolorbox}
\begin{align}
\text{Be}\spatie c_{rs} &= Xa_{rs} - b_{rs}\\
\text{Given }\spatie a_{rs} &= a^{,}_{mk}\pdv{x^{,m}}{x^r} \pdv{x^{,k}}{x^s}\\
\text{and }\spatie b_{rs} &= b^{,}_{mk}\pdv{x^{,m}}{x^r} \pdv{x^{,k}}{x^s}\\
\text{(1) }\quad\Rightarrow\spatie c_{rs} &= \underbrace{(Xa^{,}_{mk}-b^{,}_{mk})}_{=c^{,}_{km}} \pdv{x^{,m}}{x^r} \pdv{x^{,k}}{x^s}\\
\ &= c^{,}_{km} \pdv{x^{,m}}{x^r} \pdv{x^{,k}}{x^s}\\
\text{Be}\spatie J &= \left |\pdv{x^{,m}}{x^r}\right |= \left |\pdv{x^{,k}}{x^s}\right |\\
\text{In (5) put  }\spatie d_{kr} &= c^{,}_{km} \pdv{x^{,m}}{x^r} \\
\Rightarrow\spatie c_{rs} &= d^{,}_{kr} \pdv{x^{,k}}{x^s}\\
\text{or in matrix form  } \spatie C &= D^T J\quad \text{with}\quad D = C^{,}J\\
\Rightarrow\spatie \left |C \right| &= \left | (C^{,}J)^T J\right |\\
\Leftrightarrow\spatie \left |C \right| &= \left | C^{,}\right | \left |J\right |\left |J\right |
\end{align}
As $ \left |J\right | \ne 0$ ( $J$ is the Jacobian of the transformation, and thus can't be zero), then $$\left |C \right| = 0 \Rightarrow \left |C^{,} \right| = 0$$.\\
So, the root of $\left |C \right| = 0 $ is also a root of $\left |C^{,} \right| = 0$ and is as a consequence, invariant.

$$\medblackdiamond$$
\newpage

\section{p78-exercise 3}
\begin{tcolorbox}
Is the form $dx^2+3dxdy+4dy^2+dz^2$ positive definite?
\end{tcolorbox}
\begin{align}
\Phi &= dx^2+3dxdy+4dy^2+dz^2\\
\text{Put (1) in the form}\spatie  \Phi &= X^2+3XY+4Y^2+Z^2\\
\text{Z has only a positive contribution: so put }\quad Z=0\quad\Rightarrow \quad \Phi &= X^2+3XY+4Y^2\\
\text{(3) can only be zero or negative if }\quad XY < 0\quad\text{:put}\quad Y & =-aX\quad (a>0)\\
\Rightarrow \Phi &= X^2-3aX^2 +4a^2X^2\\
\text{The roots of (5) are }\quad a_{1,2} &= \frac{3\pm \sqrt{9-16}}{8}
\end{align}
So, by (6) we can't get a $a \in \mathbb{R}_*$, so that (1) can be $0$ or negative. Hence,
$$\text{The form}\quad \Phi \quad \text{is positive definite}$$

$$\medblackdiamond$$
\newpage

\section{p78-exercise 4}
\begin{tcolorbox}
If $X^r, Y^r$ are uit vectors inclined at an angle $\theta$, prove that $$\sin^2 \theta = (a_{rm}a_{sn}- a_{rs}a_{mn})X^r Y^s X^m Y^n$$
\end{tcolorbox}
$X^r Y^s$ are unit vectors. So,
\begin{align}
\ a_{rm}X^rX^m = 1 \quad &\text{and}\quad a_{sn}Y^sY^n = 1\\
\text{We have}\spatie \sin^2\theta &= 1 - \cos^2\theta\\
\text{and (2.312)}\spatie \cos\theta &= a_{mn}X^mY^n\\
\Rightarrow\spatie \sin^2 \theta &= a_{rm}X^rX^m a_{sn}Y^sY^n - a_{mn}X^mY^na_{rs}X^rY^s\\
\ &= (a_{rm} a_{sn} - a_{mn}a_{rs})X^rY^sX^mY^n
\end{align}
$$\medblackdiamond$$
\newpage

\section{p78-exercise 5}
\begin{tcolorbox}
Show that, if $\theta$ is the angle between the normals to the surfaces $x^1 = C^{st}, x^2 = C^{st}$, then $$ \cos \theta = \frac{a^{12}}{\sqrt{a^{11}a^{22}}}$$
\end{tcolorbox}
\begin{align}
\text{be}\spatie \phi^{,}_1(x^1,x^2,\dots,x^N) = C^{st} \quad \phi^{,}_2(x^1,x^2,\dots,x^N) = C^{st}
\end{align}
the two equations representing $S_1, S_2$ (see page 63). We can rewrite (1) as:
\begin{align}
\ x^1 &= \phi^{,}_1(x^1,x^2,\dots,x^N) = C^{st} \\
\ x^2 &= \phi^{,}_2(x^1,x^2,\dots,x^N) = C^{st}\\
\text{From (2.622) we know that}\quad X^m = a^{mn}\partial_n \phi_{1} & ,\ Y^m = a^{mn}\partial_n \phi_{2} \ \text{are}\perp\text{vectors to the surfaces}\  \phi_{1},\phi_{2}\\
\text{We know also} \spatie \left|X^m\right |^2 &= a^{mk}X^mX^k\\
\ & = a_{mk}a^{mn}\partial_n \phi_{1}a^{kp}\partial_p \phi_{1}\\
\ & = \delta^k_k a^{kp}\partial_n \phi_{1}\partial_p \phi_{1}\\
\ & = a^{np}\partial_n \phi_{1}\partial_p \phi_{1}\\
\text{as} \ \phi_1 = x^1 = C^{st} \ \Rightarrow \ &= a^{np}\delta^1_n \delta^1_p\\
\ &= \epsilon a^{11}\\
\text{Analog, we have}\spatie \left|Y^m\right |^2 &= \epsilon a^{22}\\
\text{By definition:}\spatie \cos\theta &= \frac{a_{mn}X^mY^n}{ \left|X^r\right | \left|Y^s\right |}\\
\text{and }\spatie a_{mn}X^mY^n &= a_{mn} a^{mk}\partial_k \phi_{1} \  a^{np}\partial_p \phi_{2}\\
\ &=\delta^k_n a^{np}\partial_k \phi_{1} \ \partial_p \phi_{2}\\
\ &=a^{kp}\partial_k \phi_{1} \ \partial_p \phi_{2}\\
\text{as} \ \phi_1 = x^1 = C^{st},  \ \phi_2 = x^2 = C^{st} \ \Rightarrow \ &= a^{kp}\delta^1_k\delta^2_p\\
\ &= a^{12}\\
\text{So (12) becomes with (10), (11) and (17)} \spatie \cos\theta &= \frac{a_{12}}{ \sqrt{\epsilon a^{11}\epsilon a^{22}}}\\
&= \frac{a_{12}}{ \sqrt{ a^{11} a^{22}}}
\end{align}
$$\medblackdiamond$$
\newpage

\section{p78-exercise 6}
\begin{tcolorbox}
Let $x^1, \ x^2,\ x^3$ be rectangular Cartesian coordinates in Euclidean 3-space, and let $x^1, \ x^2$ be taken as coordinates on a surface $x^3 = f(x^1, \ x^2)$. Show that the Christoffel symbols of the second kind for the surface are $$ \Gamma^r_{mn} = \frac{f_r f_{mn}}{1+ f_n f_p}$$ the suffixes taking the values $1, \ 2$ and the subscripts indicating partial derivatives.
\end{tcolorbox}
We have (rectangular Cartesian coordinates in Euclidean 3-space)
\begin{align}
\ ds^2 &= (dx^1)^2 + (dx^2)^2+(dx^3)^2\\
\text{with} \spatie x^3 &= f(x^1, \ x^2)\\
\text{and thus } \spatie dx^3 &= \partial_1 f \ dx^1 + \partial_2 f \  dx^2\\
\Rightarrow \spatie ds^2 &= (1+ (\partial_1 f)^2) (dx^1)^2 + (1+ (\partial_2 f)^2) (dx^2)^2+ 2\partial_1 f \ \partial_2 f \ dx^1 dx^2\\
\text{put}\spatie & \left \{ \begin{array}{c}
\ f_1 = \partial_1 f\\
\ f_2 = \partial_2 f\\
\ f_{11} = \partial_{11} f\\
\ f_{22} = \partial_{22} f\\
\ f_{12} = f_{21 } = \partial_{12} f\\
\end{array}\right.\\
\text{from (4)}\spatie \left(a_{mn}\right) =& \begin{pmatrix}
 1+f_1 ^2& f_1f_2 \\
 f_1f_2& 1+f_2 ^2 \\
\end{pmatrix}\\
\Rightarrow\spatie \left|a_{mn}\right| &= (1+f_1 ^2)(1+f_2 ^2) - (f_1f_2)^2\\
\ & = 1 + f_1 ^2+f_2 ^2\\
\text{also} \spatie \left(a^{mn}\right) =& \frac{1}{1 + f_1 ^2+f_2 ^2}\begin{pmatrix}
 1+f_2 ^2& -f_1f_2 \\
 -f_1f_2& 1+f_1 ^2 \\
\end{pmatrix}
\end{align}
\begin{align}
\textbf{Calculating the Christoffels symbols:}\quad [mn,\ k] &= \half (\partial_m a_{nk}+\partial_n a_{mk}-\partial_k a_{mn})\\
\Rightarrow\spatie & \left \{ \begin{array}{c}
\ [11,\ 1] =  f_1 f_{11}\\
\ [11,\ 2] =  f_2 f_{11}\\
\ [12,\ 1] =  f_1 f_{12}\\
\ [12,\ 2] =  f_2 f_{21}\\
\ [22,\ 2] =  f_2 f_{22}\\
\end{array}\right.\\
\text{From (11) we can see that the general form is:}\quad [mn,s] &= f_{mn}f_s\\
\textbf{Calculating the Christoffels symbols:}\quad \Gamma^r_{mn} &= a_{rs}[mn,s]\\ 
\text{(13) with (12):}\quad \Gamma^r_{mn} &= a_{rs}f_{mn}f_s = f_{mn}(a^{rs}f_s)\\
\text{put } \Delta &= \frac{1}{1 + f_1 ^2+f_2 ^2}=\frac{1}{1 + f_p f_p} \\
\Rightarrow\spatie  \left \{ \begin{array}{ll}
\Gamma^1_{mn} & = (a_{11} f_1 + a_{12} f_2)f_{mn}\\
\ & =  \Delta(f_1  + f_2^2f_1 - f_1f_2^2)f_{mn}\\
\ & =  \Delta f_1 f_{mn}\\
\end{array}\right. & \\\\
\Gamma^2_{mn} & = (a_{21} f_1 + a_{22} f_2)f_{mn}\\
\ & =  \Delta(- f_1^2f_2+f_2   + f_2f_1^2)f_{mn}\\
\ & =  \Delta f_2 f_{mn}\\
\end{align}
$$\Rightarrow\quad \Gamma^r_{mn} = \frac{f_r f_{mn}}{1 + f_p f_p}$$
$$\medblackdiamond$$
\newpage

\section{p78-exercise 7}
\begin{tcolorbox}
Write down the differential equations of the geodesics on a sphere, using colatitude $\theta$ and the azimuth $\phi$ as coordinates. Integrate the differential equations and obtain a finite equation $$ A\sin \theta \cos \phi + B \sin \theta \sin \phi + C\cos\theta = 0$$
where $A,B,C$ are arbitrary constants.
\end{tcolorbox}
We will first find the solution, starting from the variational principle , defining a geodesic.
In spherical coordinates we have (see exercise page 27) $ds^2 = dr^2 +  r^2\sin^2(\theta)d\phi^2+ r^2d\theta^2$.\\
As $r=R= C^{st}$ this reduces to
\begin{align}
\ ds^2 = R^2\sin^2(\theta)d\phi^2+ R^2d\theta^2
\end{align}
So the length of a curve on the sphere from a point $P_1$ to another point $P_2$ , the curve being determined by $\theta = \theta(u)\quad \phi = \phi(u)$ is:\\
\begin{align}
\ L &= R\int_{P_1}^{P_2} = \sqrt{\sin^2(\theta)d\phi^2+ d\theta^2}du\\
\text{Be}\quad \theta &= u \quad \phi = \phi(\theta)\\
\Rightarrow \quad  L &= R\int_{\theta_1}^{\theta_2} = \sqrt{1+\sin^2(\theta)(\dv{\phi}{\theta})^2}d\theta
\end{align}
Applying the variational principle on L and using the Euler-Langrange equations:
\begin{align}
 \dv{\pdv{\mathcal{L}}{\dot{\phi}}}{\theta} - \pdv{\mathcal{L}}{\phi}&=0\\
 \text{with}\quad \mathcal{L}& = \sqrt{1+\sin^2(\theta)(\dot{\phi})^2}\\
 \text{as}\quad  \pdv{\mathcal{L}}{\phi}&=0\\
 \text{(5) becomes:} \quad \dv{\pdv{\mathcal{L}}{\dot{\phi}}}{\theta} &=0\\
 \Leftrightarrow \quad \pdv{\mathcal{L}}{\dot{\phi}} &= C\quad \ \text{(= constant)}\\
\text{with}\quad \pdv{\mathcal{L}}{\dot{\phi}} &= \pdv{\sqrt{1+\sin^2 \theta   \  \dot{\phi}^2 }}{\dot{\phi}}= \frac{\sin^2 \theta \  \dot{\phi}}{ \sqrt{1+\sin^2 \theta \ \dot{\phi}^2 }}\\
\text{(9) and (10):}\quad C &= \frac{\sin^2 \theta \  \dot{\phi}}{ \sqrt{1+\sin^2 \theta \ \dot{\phi}^2 }} \\
\text{or}\quad \dot{\phi} &= \frac{C}{\sin \theta \sqrt{\sin^2 \theta - C^2}}
\end{align}
Solving the ODE (12).
 \\Put $u = \cot \theta \quad \Rightarrow \quad du = - \csc^2 d\theta = -\frac{1}{\sin^2\theta} d\theta$. So,  
\begin{align}
\phi &= -C\int \frac{\sin \theta}{ \sqrt{\sin^2 \theta - C^2}}du\\
&= -C\int \frac{du}{ \sqrt{1- \frac{C^2 }{\sin^2 \theta}}}\\
&= -C\int \frac{du}{ \sqrt{1- C^2 - C^2 \cot^2 \theta}}\\
&= -C\int \frac{du}{ \sqrt{1- C^2 - C^2 u^2}}\\
\text{be}\quad a&= \frac{\sqrt{1-C^2}}{C}\\
\text{(16) becomes}\quad \phi &= -\int \frac{1}{ \sqrt{a^2 -  u^2}}du\\
\text{put }\quad u &= av\\
\text{(18) becomes}\quad \phi &= -\int \frac{1}{ \sqrt{1 -  v^2}}dv\\
\ &= -\arccos v + C^{st}\\
\ &= -\arccos \frac{u}{a}  + \phi_0\\
\text{or:}\quad \frac{u}{a} &= \cos (\phi - \phi_0)  \ \text{(by choosing an adequate}\ \phi_0\text{)}\\
\text{so :}\quad \cot\theta &= a \cos (\phi - \phi_0)  \\
\text{expanding} \  \cos (\phi - \phi_0)\  \text{gives:} \quad  \frac{\cos\theta}{\sin\theta} &= \ A\cos\phi + B\sin\phi\\
\text{or:} \quad  A\cos\phi \sin\theta &+ B\sin\phi\sin\theta -\cos\theta=0
\end{align}
$$\meddiamond$$
\newpage
Finding the geodesics from the tensorial formula's.\\
Note: For ease of notation we put $R=1$ without losing any general solutions.

\begin{align}
\text{from (1) we get:}\quad (a_{mn}) &= \begin{pmatrix}
 1&  0\\
0 & \sin^2\theta \\
\end{pmatrix}\\
\text{and}\quad (a^{mn}) &= \begin{pmatrix}
 \frac{1}{\sin^2\theta}&  0\\
0 & 1 \\
\end{pmatrix}\\
\text{hence:}\quad & \left \{ \begin{array}{ll}
\Gamma^1_{11}  = 0&\Gamma^2_{11}  = 0\\
\Gamma^1_{12}  = 0&\Gamma^2_{12}  = \cot\theta\\
\Gamma^1_{22}  = -\cos\theta\sin\theta&\Gamma^2_{22}  = 0\\
\end{array}\right.
\end{align}
Finding the geodesics from the tensorial formula's, implies solving $2^{nd}$ order ODE's. In order to find the simpliest form to solve , we write down three possible forms of the geodesic equations:
\begin{align}
\text{arc-length s as independent variable}\quad& \left \{ \begin{array}{ll}
\ (a)&\dv[2]{\phi}{s} + 2 \cot\theta\dv{\phi}{s} \dv{\theta}{s} = 0\\\\
\ (b)&\dv[2]{\theta}{s} - \sin\theta\cos\theta(\dv{\phi}{s})^2  = 0\\\\
\ (c)&\ (\dv{\theta}{s})^2+\sin^2\theta(\dv{\phi}{s})^2 = 1
\end{array}\right.\\
\theta \text{ as independent variable}\quad& \left \{ \begin{array}{l}
\lambda =  - \sin\theta\cos\theta(\dv{\phi}{\theta})^2\\\\
\dv[2]{\phi}{\theta}  = \lambda \dv{\phi}{\theta}- 2 \cot\theta\dv{\phi}{\theta}  \\
\end{array}\right.\\
\Rightarrow \quad \dv[2]{\phi}{\theta}  &= - \sin\theta\cos\theta(\dv{\phi}{\theta})^3- 2 \cot\theta\dv{\phi}{\theta}  \\
\phi \text{ as independent variable}\quad& \left \{ \begin{array}{l}
\lambda =  2 \cot\theta\dv{\theta}{\phi}\\\\
\dv[2]{\theta}{\phi}  = \lambda \dv{\theta}{\phi} + \sin\theta\cos\theta(\dv{\theta}{\phi})^2 \\
\end{array}\right.\\
\Rightarrow \quad \dv[2]{\theta}{\phi}  &= 2 \cot\theta(\dv{\theta}{\phi})^2 + \sin\theta\cos\theta(\dv{\theta}{\phi})^2 \\
\
\end{align}
Inspection shows hat the expression (32) and (34) are quite complicated while using (30b) and (30c) we can get an expression of the form
\begin{align}
\ddot{\theta} - \sin\theta\cos\theta\left(\frac{1 - \dot{\theta}^2}{\sin^2\theta}\right)&= 0\\
\text{or:}\quad \ddot{\theta} - \cot\theta\left( 1-\dot{\theta}^2\right) &= 0\\
\text{Put }\ u(\theta)= \dot{\theta}\quad\Rightarrow\quad \ddot{\theta} &= \dot{u}= \dot{u}u\\
\text{(37) can be written as:}\quad \dot{u}u - \cot\theta\left( 1-u^2\right) &= 0\\
\text{or}\quad \frac{\dot{u}u}{\left( 1-u^2\right)} &= \cot\theta\\
\text{or}\quad \frac{u}{\left( 1-u^2\right)}du &= \cot\theta d\theta\\
\Rightarrow\quad -\half \log (1-u^2) &= -\log\csc\theta\\
\Rightarrow\quad \sqrt{(1-u^2)} &= \csc\theta\\
\Rightarrow\quad u &= \sqrt{1-\csc^2\theta}\\
\Rightarrow\quad  ds &= \frac{d\theta}{ \sqrt{1-\csc^2\theta}} 
\end{align}
$$\medblackdiamond$$
\newpage